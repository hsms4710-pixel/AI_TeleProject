#!/usr/bin/env python3
"""
å®Œæ•´çš„ CSIBERT å®éªŒè¿è¡Œå™¨

æ•´åˆäº† model_validation.py çš„åŸºç¡€éªŒè¯å’Œ experiments_extended.py çš„é«˜çº§å®éªŒ
æ”¯æŒè¿è¡Œæ‰€æœ‰é«˜çº§å®éªŒæ–¹æ³•
"""

import torch
import numpy as np
import scipy.io
import argparse
from pathlib import Path

from model_validation import CSIBERTValidator
from experiments_extended import AdvancedCSIBERTExperiments
from model import CSIBERT


def load_and_preprocess_data(data_path):
    """åŠ è½½å’Œé¢„å¤„ç† CSI æ•°æ®"""
    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")
    
    cell_data = scipy.io.loadmat(data_path)['multi_cell_csi']
    
    def preprocess_csi_matrix(csi_matrix):
        csi_real = np.real(csi_matrix)
        csi_imag = np.imag(csi_matrix)
        csi_real_normalized = (csi_real - np.mean(csi_real)) / (np.std(csi_real) + 1e-8)
        csi_imag_normalized = (csi_imag - np.mean(csi_imag)) / (np.std(csi_imag) + 1e-8)
        csi_combined = np.stack([csi_real_normalized, csi_imag_normalized], axis=-1)
        time_dim = csi_combined.shape[0]
        feature_dim = np.prod(csi_combined.shape[1:])
        return csi_combined.reshape(time_dim, feature_dim)
    
    # é¢„å¤„ç†æ•°æ®
    preprocessed_data = []
    sequence_lengths = []
    for cell_idx in range(cell_data.shape[0]):
        for ue_idx in range(cell_data.shape[1]):
            ue_data = cell_data[cell_idx, ue_idx]
            for scenario in ue_data[0]:
                processed_csi = preprocess_csi_matrix(scenario)
                preprocessed_data.append(processed_csi)
                sequence_lengths.append(processed_csi.shape[0])
    
    # å¡«å……æ•°æ®
    max_sequence_length = max(sequence_lengths)
    feature_dim = preprocessed_data[0].shape[-1]
    
    padded_data = np.zeros((len(preprocessed_data), max_sequence_length, feature_dim), dtype=np.float32)
    attention_masks = np.zeros((len(preprocessed_data), max_sequence_length), dtype=np.float32)
    
    for i, sequence in enumerate(preprocessed_data):
        seq_len = sequence.shape[0]
        padded_data[i, :seq_len, :] = sequence
        attention_masks[i, :seq_len] = 1
    
    print(f"âœ… æ•°æ®å½¢çŠ¶: {padded_data.shape}")
    return padded_data, attention_masks, feature_dim


def load_model(model_path, feature_dim, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ¤– åŠ è½½æ¨¡å‹: {model_path}")
    
    checkpoint = torch.load(model_path, map_location=device)
    
    # æ¨æ–­æ¨¡å‹é…ç½®
    num_hidden_layers = checkpoint.get('num_hidden_layers', 
                                       checkpoint.get('model_config', {}).get('num_hidden_layers', 12))
    
    model = CSIBERT(
        feature_dim=feature_dim,
        num_hidden_layers=num_hidden_layers,
        hidden_size=checkpoint.get('model_config', {}).get('hidden_size', 256),
        num_attention_heads=checkpoint.get('model_config', {}).get('num_attention_heads', 4)
    )
    
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (layers={num_hidden_layers})")
    return model


def main():
    parser = argparse.ArgumentParser(description='CSIBERT å®Œæ•´å®éªŒè¿è¡Œå™¨')
    parser.add_argument('--model', type=str, default='checkpoints/best_model.pt',
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--data', type=str, 
                       default='foundation_model_data/csi_data_massive_mimo.mat',
                       help='CSI æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--device', type=str, default=None,
                       choices=['cuda', 'cpu', 'mps'],
                       help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--mode', type=str, default='all',
                       choices=['basic', 'advanced', 'all'],
                       help='è¿è¡Œæ¨¡å¼: basic(åŸºç¡€éªŒè¯), advanced(é«˜çº§å®éªŒ), all(å…¨éƒ¨)')
    parser.add_argument('--output', type=str, default='validation_results',
                       help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    if args.device:
        device = torch.device(args.device)
    else:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print("\n" + "="*70)
    print("ğŸš€ CSIBERT å®Œæ•´å®éªŒè¿è¡Œå™¨")
    print("="*70)
    print(f"è®¾å¤‡: {device}")
    print(f"æ¨¡å¼: {args.mode}")
    print(f"æ¨¡å‹: {args.model}")
    print(f"æ•°æ®: {args.data}")
    print("="*70 + "\n")
    
    # åŠ è½½æ•°æ®å’Œæ¨¡å‹
    try:
        padded_data, attention_masks, feature_dim = load_and_preprocess_data(args.data)
        model = load_model(args.model, feature_dim, device)
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºæ©ç æ•°æ®
    masked_data = np.copy(padded_data)
    masked_data[:, ::10, :] = 0  # æ©ç æ¯ç¬¬10ä¸ªæ ·æœ¬
    
    # è¿è¡ŒåŸºç¡€éªŒè¯ (ä½¿ç”¨ model_validation.py)
    if args.mode in ['basic', 'all']:
        print("\n" + "="*70)
        print("ğŸ“‹ è¿è¡ŒåŸºç¡€éªŒè¯æµ‹è¯•")
        print("="*70 + "\n")
        
        try:
            validator = CSIBERTValidator(args.model, args.data, device=device)
            validator.run_all_tests()
        except Exception as e:
            print(f"âŒ åŸºç¡€éªŒè¯å¤±è´¥: {e}")
    
    # è¿è¡Œé«˜çº§å®éªŒ (ä½¿ç”¨ experiments_extended.py)
    if args.mode in ['advanced', 'all']:
        print("\n" + "="*70)
        print("ğŸ”¬ è¿è¡Œé«˜çº§å®éªŒ")
        print("="*70 + "\n")
        
        try:
            experiments = AdvancedCSIBERTExperiments(
                model=model,
                padded_data=padded_data,
                masked_data=masked_data,
                feature_dim=feature_dim,
                device=device,
                attention_masks=attention_masks,
                output_dir=args.output
            )
            
            results = experiments.run_all_advanced_experiments()
            
            # ä¿å­˜ç»“æœæ€»ç»“
            import json
            with open(f"{args.output}/advanced_experiments_summary.json", 'w') as f:
                # è½¬æ¢ DataFrame ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
                summary = {}
                for key, val in results.items():
                    if hasattr(val, 'to_dict'):
                        summary[key] = val.to_dict()
                    else:
                        summary[key] = str(val)
                json.dump(summary, f, indent=2)
                print(f"\nâœ… ç»“æœæ€»ç»“å·²ä¿å­˜: {args.output}/advanced_experiments_summary.json")
        
        except Exception as e:
            print(f"âŒ é«˜çº§å®éªŒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*70)
    print("âœ¨ å®éªŒè¿è¡Œå®Œæˆï¼")
    print(f"ğŸ“Š ç»“æœä¿å­˜åœ¨: {args.output}/")
    print("="*70 + "\n")


if __name__ == '__main__':
    main()

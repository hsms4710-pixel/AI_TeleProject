#!/usr/bin/env python3
"""
CSIBERT WebUI - Gradio å¯è§†åŒ–è®­ç»ƒç•Œé¢

æœ¬æ¨¡å—æä¾›å‹å¥½çš„ Web ç•Œé¢ç”¨äºï¼š
- ä¸€é”®è®­ç»ƒ CSIBERT æ¨¡å‹
- å®æ—¶æŸ¥çœ‹è®­ç»ƒè¿›åº¦å’ŒæŸå¤±æ›²çº¿
- åŠ è½½å’Œç®¡ç†å·²ä¿å­˜çš„æ¨¡å‹
- è¿è¡Œé«˜çº§å®éªŒå’Œå¯è§†åŒ–åˆ†æ
- æ¨¡å‹éªŒè¯å’Œæ€§èƒ½è¯„ä¼°

ä½¿ç”¨æ–¹æ³•:
    python webui/app.py
    
ç„¶ååœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://localhost:7860
"""

import os
import sys
import json
import gradio as gr
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import threading

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# å¯¼å…¥è®­ç»ƒç›¸å…³æ¨¡å—
import torch
from torch.utils.data import DataLoader, TensorDataset
from model import CSIBERT

# æ£€æµ‹è®¾å¤‡
if torch.cuda.is_available():
    device = torch.device("cuda")
elif torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    device = torch.device("cpu")

# å¯¼å…¥æ•°æ®å¤„ç†å‡½æ•°ï¼ˆä» train.pyï¼‰
def load_csi_data(file_path):
    """åŠ è½½ CSI æ•°æ®"""
    from scipy.io import loadmat
    mat_data = loadmat(file_path)
    csi_data = mat_data['CSI_data']
    return csi_data

def preprocess_csi_matrix(csi_matrix):
    """
    é¢„å¤„ç† CSI çŸ©é˜µ
    
    Args:
        csi_matrix: CSI æ•°æ®æ•°ç»„
        
    Returns:
        processed_data_list: é¢„å¤„ç†åçš„æ•°æ®åˆ—è¡¨ï¼ˆå˜é•¿åºåˆ—ï¼‰
    """
    num_samples = csi_matrix.shape[0]
    processed_data_list = []
    
    for i in range(num_samples):
        sample = csi_matrix[i]
        
        # å¤„ç†å¤æ•°æ•°æ®
        if np.iscomplexobj(sample):
            real_part = np.real(sample)
            imag_part = np.imag(sample)
            sample = np.stack([real_part, imag_part], axis=-1)
        else:
            if sample.ndim == 2:
                sample = np.expand_dims(sample, axis=-1)
        
        # å±•å¹³ä¸º 2D: (time_steps, features)
        if sample.ndim == 3:
            sample = sample.reshape(sample.shape[0], -1)
        
        # å½’ä¸€åŒ–
        mean = np.mean(sample, axis=0, keepdims=True)
        std = np.std(sample, axis=0, keepdims=True) + 1e-8
        sample = (sample - mean) / std
        
        processed_data_list.append(sample.astype(np.float32))
    
    return processed_data_list


class TrainingManager:
    """è®­ç»ƒç®¡ç†å™¨"""
    
    def __init__(self):
        self.model = None
        self.model_config = None
        self.current_model_path = None
        self.training_active = False
        self.status_log = []
        
        # å¯åŠ¨æ—¶æ‰«æå¯ç”¨æ¨¡å‹
        self.available_models = self.scan_available_models()
        
        # è‡ªåŠ¨åŠ è½½æœ€æ–°æ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.available_models:
            self.auto_load_model(self.available_models[0])
    
    def scan_available_models(self):
        """æ‰«æcheckpointsç›®å½•ä¸‹æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
        checkpoint_dir = PROJECT_ROOT / "checkpoints"
        if not checkpoint_dir.exists():
            return []
        
        models = []
        for model_file in checkpoint_dir.glob("*.pt"):
            try:
                # å°è¯•åŠ è½½æ¨¡å‹è·å–ä¿¡æ¯
                checkpoint = torch.load(model_file, map_location='cpu')
                model_info = {
                    'path': str(model_file),
                    'name': model_file.name,
                    'hidden_size': checkpoint.get('hidden_size', 'Unknown'),
                    'num_layers': checkpoint.get('num_hidden_layers', 'Unknown'),
                    'num_heads': checkpoint.get('num_attention_heads', 'Unknown'),
                    'feature_dim': checkpoint.get('feature_dim', 'Unknown'),
                    'modified_time': model_file.stat().st_mtime
                }
                models.append(model_info)
            except Exception as e:
                print(f"[WebUI] è·³è¿‡æ— æ•ˆæ¨¡å‹æ–‡ä»¶: {model_file.name} - {str(e)}")
        
        # æŒ‰ä¿®æ”¹æ—¶é—´é™åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
        models.sort(key=lambda x: x['modified_time'], reverse=True)
        return models
    
    def get_model_list_display(self):
        """è·å–æ¨¡å‹åˆ—è¡¨çš„æ˜¾ç¤ºæ ¼å¼"""
        if not self.available_models:
            return []
        
        display_list = []
        for model in self.available_models:
            display_name = f"{model['name']} (H:{model['hidden_size']}, L:{model['num_layers']}, A:{model['num_heads']})"
            display_list.append(display_name)
        return display_list
    
    def log_status(self, message):
        """è®°å½•çŠ¶æ€ä¿¡æ¯"""
        self.status_log.append(message)
        print(f"[WebUI] {message}")
        return message
    
    def auto_load_model(self, model_info=None):
        """
        è‡ªåŠ¨åŠ è½½æŒ‡å®šçš„æ¨¡å‹
        
        Args:
            model_info: æ¨¡å‹ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™å°è¯•åŠ è½½best_model.pt
        """
        if model_info is None:
            # é»˜è®¤åŠ è½½best_model.pt
            checkpoint_path = PROJECT_ROOT / "checkpoints" / "best_model.pt"
            if not checkpoint_path.exists():
                self.log_status(" æœªå‘ç°æ¨¡å‹æ–‡ä»¶")
                return False
        else:
            checkpoint_path = Path(model_info['path'])
        
        try:
            self.log_status(f" æ­£åœ¨åŠ è½½æ¨¡å‹: {checkpoint_path.name}")
            checkpoint = torch.load(checkpoint_path, map_location=device)
            
            # æå–æ¨¡å‹é…ç½®
            self.model_config = {
                'feature_dim': checkpoint.get('feature_dim'),
                'hidden_size': checkpoint.get('hidden_size', 512),
                'num_hidden_layers': checkpoint.get('num_hidden_layers', 8),
                'num_attention_heads': checkpoint.get('num_attention_heads', 8)
            }
            
            # åˆå§‹åŒ–æ¨¡å‹ï¼ˆCSIBERTåªæ¥å—è¿™4ä¸ªå‚æ•°ï¼‰
            self.model = CSIBERT(
                feature_dim=self.model_config['feature_dim'],
                hidden_size=self.model_config['hidden_size'],
                num_hidden_layers=self.model_config['num_hidden_layers'],
                num_attention_heads=self.model_config['num_attention_heads']
            ).to(device)
            
            # åŠ è½½æ¨¡å‹æƒé‡
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            self.current_model_path = str(checkpoint_path)
            
            self.log_status(f" æ¨¡å‹åŠ è½½æˆåŠŸ: {checkpoint_path.name}")
            self.log_status(f" é…ç½®: Hidden={self.model_config['hidden_size']}, "
                           f"Layers={self.model_config['num_hidden_layers']}, "
                           f"Heads={self.model_config['num_attention_heads']}")
            return True
            
        except Exception as e:
            self.log_status(f" æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            self.model = None
            self.model_config = None
            self.current_model_path = None
            return False
    
    def load_model_by_name(self, model_display_name):
        """æ ¹æ®æ˜¾ç¤ºåç§°åŠ è½½æ¨¡å‹"""
        if not model_display_name:
            return " è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹"
        
        # ä»æ˜¾ç¤ºåç§°ä¸­æå–å®é™…æ–‡ä»¶å
        model_name = model_display_name.split(" (")[0]
        
        # æŸ¥æ‰¾å¯¹åº”çš„æ¨¡å‹ä¿¡æ¯
        model_info = None
        for model in self.available_models:
            if model['name'] == model_name:
                model_info = model
                break
        
        if model_info is None:
            return " æœªæ‰¾åˆ°æŒ‡å®šçš„æ¨¡å‹"
        
        # åŠ è½½æ¨¡å‹
        if self.auto_load_model(model_info):
            return f" æˆåŠŸåŠ è½½æ¨¡å‹: {model_name}\n\n{self.get_model_status()}"
        else:
            return f" æ¨¡å‹åŠ è½½å¤±è´¥"
    
    def get_model_status(self):
        """è·å–å½“å‰æ¨¡å‹çŠ¶æ€"""
        if self.model is not None:
            config_str = f"Hidden={self.model_config['hidden_size']}, Layers={self.model_config['num_hidden_layers']}, Heads={self.model_config['num_attention_heads']}"
            model_name = Path(self.current_model_path).name if self.current_model_path else "Unknown"
            return f" å·²åŠ è½½æ¨¡å‹\n æ–‡ä»¶: {model_name}\n é…ç½®: {config_str}"
        else:
            model_count = len(self.available_models)
            if model_count > 0:
                return f" æœªåŠ è½½æ¨¡å‹\n å¯ç”¨æ¨¡å‹: {model_count} ä¸ª\n è¯·ä»ä¸‹æ–¹åˆ—è¡¨é€‰æ‹©æ¨¡å‹åŠ è½½"
            else:
                return " æœªåŠ è½½æ¨¡å‹\n checkpointsç›®å½•ä¸­æ— å¯ç”¨æ¨¡å‹\n è¯·å…ˆè®­ç»ƒæ¨¡å‹"
    
    def one_click_train(self, hidden_size, num_layers, num_heads, intermediate_size, max_position, epochs, batch_size, learning_rate):
        """ä¸€é”®è®­ç»ƒï¼šæ•°æ®ç”Ÿæˆ â†’ æ•°æ®å¤„ç† â†’ æ¨¡å‹è®­ç»ƒ â†’ æµ‹è¯•"""
        self.training_active = True
        self.status_log = []
        
        try:
            self.log_status("=" * 60)
            self.log_status(" ä¸€é”®è®­ç»ƒæµç¨‹å¯åŠ¨")
            self.log_status("=" * 60)
            
            # æ­¥éª¤1: ç”Ÿæˆæ•°æ®
            self.log_status("\n æ­¥éª¤ 1/4: ç”ŸæˆCSIæ•°æ®...")
            self.log_status(" ä½¿ç”¨æ ‡å‡†é…ç½®ç”Ÿæˆæ•°æ®:")
            self.log_status("  - åŸºç«™æ•°: 10")
            self.log_status("  - ç”¨æˆ·æ•°: 200")
            self.log_status("  - å­è½½æ³¢: 64")
            self.log_status("  - åŸºç«™å¤©çº¿: 64")
            self.log_status("  - ç”¨æˆ·å¤©çº¿: 4")
            
            # TODO: è¿™é‡Œè°ƒç”¨MATLABæˆ–Pythonæ•°æ®ç”Ÿæˆè„šæœ¬
            self.log_status(" æ•°æ®ç”Ÿæˆéœ€è¦MATLABï¼Œè·³è¿‡æ­¤æ­¥éª¤")
            self.log_status(" å°è¯•åŠ è½½å·²æœ‰æ•°æ®...")
            
            # æ­¥éª¤2: åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
            self.log_status("\n æ­¥éª¤ 2/4: æ•°æ®é¢„å¤„ç†...")
            try:
                import scipy.io
                cell_data = scipy.io.loadmat('foundation_model_data/csi_data_massive_mimo.mat')['multi_cell_csi']
                self.log_status(f"âœ“ æˆåŠŸåŠ è½½æ•°æ®: {cell_data.shape}")
            except Exception as e:
                self.log_status(f" æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶: {str(e)}")
                self.log_status(" ç”Ÿæˆéšæœºæ¼”ç¤ºæ•°æ®...")
                cell_data = np.random.randn(10, 200, 64, 4, 2)
            
            # é¢„å¤„ç†æ•°æ®
            preprocessed_data = []
            self.log_status(" é¢„å¤„ç†CSIçŸ©é˜µ...")
            
            for i in range(min(500, np.prod(cell_data.shape[:2]))):
                try:
                    if cell_data.ndim >= 2:
                        cell_idx = i // cell_data.shape[1]
                        ue_idx = i % cell_data.shape[1]
                        if cell_idx < cell_data.shape[0]:
                            csi_matrix = cell_data[cell_idx, ue_idx]
                            if isinstance(csi_matrix, np.ndarray):
                                processed = preprocess_csi_matrix(csi_matrix)
                                preprocessed_data.append(processed)
                except:
                    pass
            
            if len(preprocessed_data) == 0:
                self.log_status(" é¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨éšæœºæ•°æ®")
                preprocessed_data = [np.random.randn(64, 64) for _ in range(500)]
            
            preprocessed_data = np.array(preprocessed_data)
            self.log_status(f"âœ“ é¢„å¤„ç†å®Œæˆ: {len(preprocessed_data)} ä¸ªæ ·æœ¬")
            
            # æ­¥éª¤3: æ¨¡å‹è®­ç»ƒ
            self.log_status("\n æ­¥éª¤ 3/4: æ¨¡å‹è®­ç»ƒ...")
            self.log_status(" ä½¿ç”¨é…ç½®:")
            self.log_status(f"  - Hidden Size: {hidden_size}")
            self.log_status(f"  - Num Layers: {num_layers}")
            self.log_status(f"  - Attention Heads: {num_heads}")
            self.log_status(f"  - Intermediate Size: {intermediate_size}")
            self.log_status(f"  - Max Position: {max_position}")
            self.log_status(f"  - Epochs: {epochs}")
            self.log_status(f"  - Batch Size: {batch_size}")
            self.log_status(f"  - Learning Rate: {learning_rate}")
            
            # å‡†å¤‡æ•°æ®åŠ è½½å™¨
            dataset = TensorDataset(
                torch.tensor(preprocessed_data).float(),
                torch.tensor(preprocessed_data).float()
            )
            loader = DataLoader(dataset, batch_size=int(batch_size), shuffle=True)
            
            # åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼‰
            feature_dim = preprocessed_data.shape[-1]
            self.model = CSIBERT(
                vocab_size=64,
                hidden_size=int(hidden_size),
                num_hidden_layers=int(num_layers),
                num_attention_heads=int(num_heads),
                intermediate_size=int(intermediate_size),
                max_position_embeddings=int(max_position)
            ).to(device)
            
            total_params = sum(p.numel() for p in self.model.parameters())
            self.log_status(f"âœ“ æ¨¡å‹å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
            
            optimizer = torch.optim.Adam(self.model.parameters(), lr=float(learning_rate))
            criterion = torch.nn.MSELoss()
            
            # è®­ç»ƒå¾ªç¯
            self.log_status(f"\n å¼€å§‹è®­ç»ƒ {int(epochs)} è½®...")
            
            best_loss = float('inf')
            for epoch in range(int(epochs)):
                if not self.training_active:
                    self.log_status(" è®­ç»ƒè¢«ä¸­æ–­")
                    break
                
                self.model.train()
                total_loss = 0
                
                for batch_idx, (inputs, targets) in enumerate(loader):
                    inputs = inputs.to(device)
                    targets = targets.to(device)
                    
                    optimizer.zero_grad()
                    outputs = self.model(inputs)
                    loss = criterion(outputs, targets)
                    loss.backward()
                    optimizer.step()
                    
                    total_loss += loss.item()
                
                avg_loss = total_loss / len(loader)
                
                # åªæ˜¾ç¤ºå…³é”®epoch
                if (epoch + 1) % 5 == 0 or epoch == 0:
                    self.log_status(f"âœ“ Epoch {epoch+1}/{int(epochs)} - Loss: {avg_loss:.6f}")
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if avg_loss < best_loss:
                    best_loss = avg_loss
                    checkpoint_dir = PROJECT_ROOT / "checkpoints"
                    checkpoint_dir.mkdir(exist_ok=True)
                    torch.save({
                        'model_state_dict': self.model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'epoch': epoch + 1,
                        'loss': avg_loss,
                        'config': {
                            'hidden_size': int(hidden_size),
                            'num_layers': int(num_layers),
                            'num_heads': int(num_heads),
                            'intermediate_size': int(intermediate_size),
                            'max_position': int(max_position)
                        }
                    }, checkpoint_dir / "best_model.pt")
            
            self.log_status(f"\n è®­ç»ƒå®Œæˆï¼æœ€ä½³Loss: {best_loss:.6f}")
            
            # æ­¥éª¤4: å¿«é€Ÿæµ‹è¯•
            self.log_status("\n æ­¥éª¤ 4/4: æ¨¡å‹æµ‹è¯•...")
            self.model.eval()
            
            with torch.no_grad():
                test_input = torch.tensor(preprocessed_data[:10]).float().to(device)
                test_output = self.model(test_input)
                test_loss = criterion(test_output, test_input)
                self.log_status(f"âœ“ æµ‹è¯•Loss: {test_loss.item():.6f}")
            
            self.log_status("\n" + "=" * 60)
            self.log_status(" ä¸€é”®è®­ç»ƒæµç¨‹å®Œæˆï¼")
            self.log_status("=" * 60)
            self.log_status(f" æ¨¡å‹å·²ä¿å­˜åˆ°: checkpoints/best_model.pt")
            self.log_status(f" è®­ç»ƒæ ·æœ¬æ•°: {len(preprocessed_data)}")
            self.log_status(f" æœ€ç»ˆLoss: {best_loss:.6f}")
            
            return "\n".join(self.status_log)
            
        except Exception as e:
            error_msg = f" è®­ç»ƒå‡ºé”™: {str(e)}"
            self.log_status(error_msg)
            import traceback
            self.log_status(traceback.format_exc())
            return "\n".join(self.status_log)
        
        finally:
            self.training_active = False
    
    def train_model(self, hidden_size, num_layers, num_heads, intermediate_size, max_position, epochs, batch_size, learning_rate):
        """è®­ç»ƒæ¨¡å‹"""
        self.training_active = True
        self.status_log = []
        
        try:
            self.log_status(" å¼€å§‹è®­ç»ƒæ¨¡å‹...")
            self.log_status(f" æ¨¡å‹é…ç½®:")
            self.log_status(f"  Hidden Size: {hidden_size}")
            self.log_status(f"  Num Layers: {num_layers}")
            self.log_status(f"  Attention Heads: {num_heads}")
            self.log_status(f"  Intermediate Size: {intermediate_size}")
            self.log_status(f"  Max Position: {max_position}")
            self.log_status(f" è®­ç»ƒé…ç½®:")
            self.log_status(f"  Epochs: {epochs}")
            self.log_status(f"  Batch Size: {batch_size}")
            self.log_status(f"  Learning Rate: {learning_rate}")
            
            # åŠ è½½æ•°æ®
            self.log_status("\n åŠ è½½CSIæ•°æ®...")
            try:
                cell_data = np.load("BERT4MIMO-AI4Wireless/foundation_model_data/csi_data_massive_mimo.npy", allow_pickle=True)
            except:
                self.log_status(" æœªæ‰¾åˆ°é¢„å¤„ç†æ•°æ®ï¼Œç”Ÿæˆéšæœºæ•°æ®è¿›è¡Œæ¼”ç¤º...")
                cell_data = np.random.randn(10, 5, 64, 32, 2)
            
            # é¢„å¤„ç†
            self.log_status(" æ•°æ®é¢„å¤„ç†ä¸­...")
            preprocessed_data = []
            for i in range(min(100, len(cell_data.flatten()))):
                try:
                    csi_matrix = cell_data.flatten()[i]
                    if isinstance(csi_matrix, np.ndarray) and csi_matrix.size > 0:
                        processed = preprocess_csi_matrix(csi_matrix)
                        preprocessed_data.append(processed)
                except:
                    pass
            
            if len(preprocessed_data) == 0:
                preprocessed_data = [np.random.randn(64, 64) for _ in range(100)]
            
            preprocessed_data = np.array(preprocessed_data)
            self.log_status(f"âœ“ åŠ è½½äº† {len(preprocessed_data)} ä¸ªæ ·æœ¬")
            
            # å‡†å¤‡æ•°æ®åŠ è½½å™¨
            dataset = TensorDataset(
                torch.tensor(preprocessed_data).float(),
                torch.tensor(preprocessed_data).float()
            )
            loader = DataLoader(dataset, batch_size=int(batch_size), shuffle=True)
            
            # åˆå§‹åŒ–æ¨¡å‹
            self.log_status("\n åˆå§‹åŒ–CSIBERTæ¨¡å‹...")
            self.model = CSIBERT(
                vocab_size=64,
                hidden_size=int(hidden_size),
                num_hidden_layers=int(num_layers),
                num_attention_heads=int(num_heads),
                intermediate_size=int(intermediate_size),
                max_position_embeddings=int(max_position)
            ).to(device)
            
            # è®¡ç®—æ¨¡å‹å‚æ•°é‡
            total_params = sum(p.numel() for p in self.model.parameters())
            self.log_status(f"âœ“ æ¨¡å‹å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
            
            optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)
            criterion = torch.nn.MSELoss()
            
            # è®­ç»ƒå¾ªç¯
            self.log_status("\n å¼€å§‹è®­ç»ƒå¾ªç¯...")
            for epoch in range(int(epochs)):
                if not self.training_active:
                    self.log_status(" è®­ç»ƒè¢«ä¸­æ–­")
                    break
                
                total_loss = 0
                for batch_idx, (inputs, targets) in enumerate(loader):
                    inputs = inputs.to(device)
                    targets = targets.to(device)
                    
                    optimizer.zero_grad()
                    outputs = self.model(inputs)
                    loss = criterion(outputs, targets)
                    loss.backward()
                    optimizer.step()
                    
                    total_loss += loss.item()
                
                avg_loss = total_loss / len(loader)
                self.log_status(f"âœ“ Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.6f}")
                
                # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡
                if (epoch + 1) % 5 == 0:
                    checkpoint_dir = PROJECT_ROOT / "checkpoints"
                    checkpoint_dir.mkdir(exist_ok=True)
                    torch.save(
                        self.model.state_dict(),
                        checkpoint_dir / f"model_epoch_{epoch+1}.pt"
                    )
                    self.log_status(f" å·²ä¿å­˜æ£€æŸ¥ç‚¹: epoch_{epoch+1}")
            
            self.log_status(" è®­ç»ƒå®Œæˆï¼")
            return "\n".join(self.status_log)
        
        except Exception as e:
            error_msg = f" è®­ç»ƒé”™è¯¯: {str(e)}"
            self.log_status(error_msg)
            return "\n".join(self.status_log)
        
        finally:
            self.training_active = False
    
    def stop_training(self):
        """åœæ­¢è®­ç»ƒ"""
        self.training_active = False
        self.log_status(" è®­ç»ƒåœæ­¢å‘½ä»¤å·²å‘é€")
        return "è®­ç»ƒå·²åœæ­¢"
    
    def run_experiments(self, exp_list, progress_callback=None):
        """
        è¿è¡Œå®éªŒåˆ—è¡¨
        
        Args:
            exp_list: å®éªŒåç§°åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
        Returns:
            å®éªŒç»“æœå­—ç¬¦ä¸²
        """
        if self.model is None:
            if not self.auto_load_model():
                return "âŒ æœªæ‰¾åˆ°æ¨¡å‹ï¼Œæ— æ³•è¿è¡Œå®éªŒ"
        
        results = []
        results.append("=" * 60)
        results.append("ğŸ§ª å¼€å§‹è¿è¡Œå®éªŒå¥—ä»¶")
        results.append("=" * 60)
        results.append(f"\nğŸ“‹ è®¡åˆ’è¿è¡Œ {len(exp_list)} é¡¹å®éªŒ\n")
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ•°æ®
            test_data_path = PROJECT_ROOT / "validation_data" / "test_data.npy"
            if not test_data_path.exists():
                results.append("âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ train.py ç”Ÿæˆæµ‹è¯•æ•°æ®")
                return "\n".join(results)
            
            # åŠ è½½æµ‹è¯•æ•°æ®
            test_data = np.load(test_data_path, allow_pickle=True)
            results.append(f"âœ“ å·²åŠ è½½æµ‹è¯•æ•°æ®: {len(test_data)} ä¸ªæ ·æœ¬\n")
            
            # åˆ¤æ–­å®éªŒç±»å‹
            has_basic_tests = any("Reconstruction" in exp or "Prediction" in exp or 
                                 "SNR" in exp or "Compression" in exp or 
                                 "Inference" in exp or "All Basic" in exp 
                                 for exp in exp_list)
            
            has_advanced_tests = any("Masking Ratio" in exp or "Error Distribution" in exp or
                                    "Prediction Horizon" in exp or "Baseline" in exp or
                                    "Attention" in exp or "All Advanced" in exp
                                    for exp in exp_list)
            
            # è¿è¡ŒåŸºç¡€éªŒè¯å®éªŒ
            if has_basic_tests:
                results.append("ğŸ“Š åŸºç¡€éªŒè¯å®éªŒ")
                results.append("-" * 60)
                
                from model_validation import CSIBERTValidator
                validator = CSIBERTValidator(
                    model_path=str(PROJECT_ROOT / "checkpoints" / "best_model.pt"),
                    device=str(device)
                )
                
                for i, exp_name in enumerate(exp_list, 1):
                    if "Reconstruction Error" in exp_name:
                        results.append(f"\n[{i}] ğŸ” é‡æ„è¯¯å·®æµ‹è¯•")
                        validator.test_reconstruction_error(mask_ratio=0.15)
                        results.append("  âœ“ å®Œæˆ - ç”Ÿæˆå›¾è¡¨: reconstruction_error.png")
                        
                    elif "Prediction Accuracy" in exp_name:
                        results.append(f"\n[{i}] ğŸ“ˆ é¢„æµ‹å‡†ç¡®åº¦æµ‹è¯•")
                        validator.test_prediction_accuracy(history_len=10, predict_steps=[1, 3, 5, 10])
                        results.append("  âœ“ å®Œæˆ - ç”Ÿæˆå›¾è¡¨: prediction_accuracy.png")
                        
                    elif "SNR Robustness" in exp_name:
                        results.append(f"\n[{i}] ğŸ“¡ SNRé²æ£’æ€§æµ‹è¯•")
                        validator.test_snr_robustness(snr_range=[-10, 0, 10, 20, 30])
                        results.append("  âœ“ å®Œæˆ - ç”Ÿæˆå›¾è¡¨: snr_robustness.png")
                        
                    elif "Compression" in exp_name:
                        results.append(f"\n[{i}] ğŸ—œï¸ å‹ç¼©è´¨é‡æµ‹è¯•")
                        validator.test_compression_ratio(compression_ratios=[10, 20, 30, 40, 50])
                        results.append("  âœ“ å®Œæˆ - ç”Ÿæˆå›¾è¡¨: compression_quality.png")
                        
                    elif "Inference Speed" in exp_name:
                        results.append(f"\n[{i}] âš¡ æ¨ç†é€Ÿåº¦æµ‹è¯•")
                        validator.test_inference_speed(batch_sizes=[1, 8, 16, 32])
                        results.append("  âœ“ å®Œæˆ - ç”Ÿæˆå›¾è¡¨: inference_speed.png")
                        
                    elif "All Basic" in exp_name:
                        results.append(f"\n[{i}] ğŸ”° è¿è¡Œæ‰€æœ‰åŸºç¡€æµ‹è¯•")
                        validator.run_all_tests()
                        results.append("  âœ“ å®Œæˆ - ç”Ÿæˆå®Œæ•´æŠ¥å‘Š: validation_results/")
                    
                    if progress_callback:
                        progress_callback(i / len(exp_list))
            
            # è¿è¡Œé«˜çº§å®éªŒ
            if has_advanced_tests:
                results.append("\n\nğŸ”¬ é«˜çº§å®éªŒåˆ†æ")
                results.append("-" * 60)
                
                from experiments_extended import AdvancedCSIBERTExperiments
                advanced_exp = AdvancedCSIBERTExperiments(
                    model=self.model,
                    test_data=test_data,
                    device=device,
                    output_dir=str(PROJECT_ROOT / "advanced_experiments")
                )
                
                for i, exp_name in enumerate(exp_list, 1):
                    if "Masking Ratio" in exp_name:
                        results.append(f"\n[{i}] ğŸ­ æ©ç æ¯”ç‡æ•æ„Ÿæ€§åˆ†æ")
                        advanced_exp.experiment_1_masking_ratio_sensitivity()
                        results.append("  âœ“ å®Œæˆ - æµ‹è¯•äº†15ç§æ©ç æ¯”ç‡")
                        
                    elif "Error Distribution" in exp_name:
                        results.append(f"\n[{i}] ğŸ“Š è¯¯å·®åˆ†å¸ƒåˆ†æ")
                        advanced_exp.experiment_2_error_distribution()
                        results.append("  âœ“ å®Œæˆ - ç”Ÿæˆè¯¯å·®ç»Ÿè®¡æŠ¥å‘Š")
                        
                    elif "Prediction Horizon" in exp_name:
                        results.append(f"\n[{i}] ğŸ”® é¢„æµ‹æ­¥é•¿åˆ†æ")
                        advanced_exp.experiment_3_prediction_horizon()
                        results.append("  âœ“ å®Œæˆ - æµ‹è¯•äº†å¤šä¸ªé¢„æµ‹æ­¥é•¿")
                        
                    elif "Baseline" in exp_name:
                        results.append(f"\n[{i}] ğŸ“ åŸºçº¿æ–¹æ³•å¯¹æ¯”")
                        advanced_exp.experiment_4_baseline_comparison()
                        results.append("  âœ“ å®Œæˆ - å¯¹æ¯”äº†ä¼ ç»Ÿæ–¹æ³•")
                        
                    elif "Attention" in exp_name:
                        results.append(f"\n[{i}] ğŸ‘ï¸ æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–")
                        advanced_exp.experiment_5_attention_visualization(num_samples=3)
                        results.append("  âœ“ å®Œæˆ - å¯è§†åŒ–äº†æ³¨æ„åŠ›çƒ­åŠ›å›¾")
                        
                    elif "All Advanced" in exp_name:
                        results.append(f"\n[{i}] ğŸš€ è¿è¡Œæ‰€æœ‰é«˜çº§å®éªŒ")
                        advanced_exp.run_all_experiments()
                        results.append("  âœ“ å®Œæˆ - ç”Ÿæˆå®Œæ•´é«˜çº§å®éªŒæŠ¥å‘Š")
                    
                    if progress_callback:
                        progress_callback(i / len(exp_list))
            
            results.append("\n" + "=" * 60)
            results.append("âœ… å®éªŒå¥—ä»¶æ‰§è¡Œå®Œæˆ")
            results.append("=" * 60)
            results.append("\nğŸ“ ç»“æœä¿å­˜ä½ç½®:")
            if has_basic_tests:
                results.append("  - åŸºç¡€éªŒè¯: ./validation_results/")
            if has_advanced_tests:
                results.append("  - é«˜çº§å®éªŒ: ./advanced_experiments/")
            
        except Exception as e:
            import traceback
            results.append(f"\nâŒ å®éªŒå¥—ä»¶é”™è¯¯: {str(e)}")
            results.append(f"\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")
        
        return "\n".join(results)


def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    manager = TrainingManager()
    
    with gr.Blocks(title="CSIBERT WebUI - MIMO CSIå¤„ç†", theme=gr.themes.Soft()) as app:
        
        gr.Markdown("""
        #  CSIBERT WebUI - æ— çº¿é€šä¿¡CSIå¤„ç†æ¡†æ¶
        
        åŸºäº BERT æ¶æ„çš„å¤§è§„æ¨¡ MIMO ä¿¡é“çŠ¶æ€ä¿¡æ¯ (CSI) å¤„ç†å¹³å°
        """)
        
        with gr.Tabs():
            
            # æ ‡ç­¾1: ä¸€é”®è®­ç»ƒ
            with gr.TabItem(" ä¸€é”®è®­ç»ƒ"):
                gr.Markdown("## ä¸€é”®å®Œæ•´æµç¨‹ - æ•°æ®ç”Ÿæˆåˆ°æ¨¡å‹æµ‹è¯•")
                
                gr.Markdown("""
                ** å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹**ï¼ŒåŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š
                
                1.  **æ•°æ®ç”Ÿæˆ** - ç”ŸæˆCSIè®­ç»ƒæ•°æ®ï¼ˆå¦‚å·²å­˜åœ¨åˆ™è·³è¿‡ï¼‰
                2.  **æ•°æ®é¢„å¤„ç†** - å½’ä¸€åŒ–ã€å¡«å……ã€æ©ç å¤„ç†
                3.  **æ¨¡å‹è®­ç»ƒ** - å¯è‡ªå®šä¹‰æ‰€æœ‰å‚æ•°
                4.  **æ¨¡å‹æµ‹è¯•** - å¿«é€ŸéªŒè¯æ¨¡å‹æ€§èƒ½
                """)
                
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("###  æ¨¡å‹æ¶æ„å‚æ•°")
                        
                        quick_hidden_size = gr.Slider(
                            minimum=128, maximum=1024, value=512, step=64,
                            label="Hidden Size",
                            info="è½»é‡:256 | æ ‡å‡†:512 | åŸå§‹:768"
                        )
                        quick_num_layers = gr.Slider(
                            minimum=2, maximum=24, value=8, step=2,
                            label="Num Layers",
                            info="è½»é‡:4 | æ ‡å‡†:8 | åŸå§‹:12"
                        )
                        quick_num_heads = gr.Slider(
                            minimum=2, maximum=16, value=8, step=2,
                            label="Attention Heads",
                            info="è½»é‡:4 | æ ‡å‡†:8 | åŸå§‹:12"
                        )
                        quick_intermediate = gr.Slider(
                            minimum=512, maximum=4096, value=2048, step=256,
                            label="Intermediate Size",
                            info="è½»é‡:1024 | æ ‡å‡†:2048 | åŸå§‹:3072"
                        )
                        quick_max_position = gr.Slider(
                            minimum=512, maximum=8192, value=4096, step=512,
                            label="Max Position",
                            info="è½»é‡:2048 | æ ‡å‡†:4096 | åŸå§‹:4096"
                        )
                    
                    with gr.Column():
                        gr.Markdown("###  è®­ç»ƒé…ç½®å‚æ•°")
                        
                        quick_epochs = gr.Slider(
                            minimum=1, maximum=500, value=50, step=1,
                            label="Epochs",
                            info="è½»é‡:10 | æ ‡å‡†:50 | åŸå§‹:200"
                        )
                        quick_batch_size = gr.Slider(
                            minimum=8, maximum=256, value=32, step=8,
                            label="Batch Size",
                            info="è½»é‡:16 | æ ‡å‡†:32 | åŸå§‹:64"
                        )
                        quick_lr = gr.Slider(
                            minimum=1e-5, maximum=1e-2, value=1e-4, step=1e-5,
                            label="Learning Rate",
                            info="æ¨è:1e-4 | èŒƒå›´:1e-5~1e-2"
                        )
                        
                        gr.Markdown("""
                        ###  å¿«é€Ÿé¢„è®¾
                        ç‚¹å‡»æŒ‰é’®å¿«é€Ÿå¡«å……å‚æ•°ï¼š
                        """)
                        
                        with gr.Row():
                            preset_light_btn = gr.Button("è½»é‡åŒ–", size="sm")
                            preset_standard_btn = gr.Button("æ ‡å‡†", size="sm", variant="primary")
                            preset_original_btn = gr.Button("åŸå§‹", size="sm")
                
                gr.Markdown("""
                **é¢„è®¡æ—¶é—´**: æ ¹æ®é…ç½®5-150åˆ†é’Ÿ  
                **æ˜¾å­˜éœ€æ±‚**: è½»é‡2GB | æ ‡å‡†4GB | åŸå§‹8GB
                """)
                
                with gr.Row():
                    quick_train_btn = gr.Button(" å¼€å§‹å®Œæ•´æµç¨‹", scale=2, variant="primary", size="lg")
                    quick_stop_btn = gr.Button(" åœæ­¢", scale=1, variant="stop")
                
                quick_status = gr.Textbox(
                    label=" æµç¨‹çŠ¶æ€",
                    interactive=False,
                    lines=20,
                    max_lines=40
                )
                
                # é¢„è®¾é…ç½®æŒ‰é’®äº‹ä»¶
                def apply_light_preset():
                    return 256, 4, 4, 1024, 2048, 10, 16, 1e-4
                
                def apply_standard_preset():
                    return 512, 8, 8, 2048, 4096, 50, 32, 1e-4
                
                def apply_original_preset():
                    return 768, 12, 12, 3072, 4096, 200, 64, 1e-4
                
                preset_light_btn.click(
                    fn=apply_light_preset,
                    outputs=[quick_hidden_size, quick_num_layers, quick_num_heads, 
                            quick_intermediate, quick_max_position, quick_epochs, 
                            quick_batch_size, quick_lr]
                )
                
                preset_standard_btn.click(
                    fn=apply_standard_preset,
                    outputs=[quick_hidden_size, quick_num_layers, quick_num_heads, 
                            quick_intermediate, quick_max_position, quick_epochs, 
                            quick_batch_size, quick_lr]
                )
                
                preset_original_btn.click(
                    fn=apply_original_preset,
                    outputs=[quick_hidden_size, quick_num_layers, quick_num_heads, 
                            quick_intermediate, quick_max_position, quick_epochs, 
                            quick_batch_size, quick_lr]
                )
                
                quick_train_btn.click(
                    fn=manager.one_click_train,
                    inputs=[quick_hidden_size, quick_num_layers, quick_num_heads, 
                           quick_intermediate, quick_max_position, quick_epochs, 
                           quick_batch_size, quick_lr],
                    outputs=quick_status
                )
                
                quick_stop_btn.click(
                    fn=manager.stop_training,
                    outputs=quick_status
                )
            
            # æ ‡ç­¾2: å¯¼å…¥æ•°æ®è®­ç»ƒ
            with gr.TabItem(" å¯¼å…¥æ•°æ®è®­ç»ƒ"):
                gr.Markdown("## è‡ªå®šä¹‰é…ç½®è®­ç»ƒ")
                
                with gr.Row():
                    with gr.Column():
                        # é¢„è®¾é…ç½®é€‰æ‹©ï¼ˆä»…ç”¨äºå¿«é€Ÿå¡«å……ï¼‰
                        preset = gr.Radio(
                            choices=["è½»é‡åŒ–é…ç½®", "æ ‡å‡†é…ç½®", "åŸå§‹é…ç½®"],
                            value="æ ‡å‡†é…ç½®",
                            label=" é¢„è®¾é…ç½®ï¼ˆå¯é€‰ï¼‰",
                            info="ç‚¹å‡»é¢„è®¾ä¼šè‡ªåŠ¨å¡«å……å‚æ•°ï¼Œä½†æ‰€æœ‰å‚æ•°éƒ½å¯è‡ªç”±ä¿®æ”¹"
                        )
                    
                    with gr.Column():
                        gr.Markdown("""
                        ###  é…ç½®å‚è€ƒï¼ˆæ‰€æœ‰å‚æ•°å¯è‡ªå®šä¹‰ï¼‰
                        
                        | é…ç½® | Hidden | Layers | Heads | Epochs | Batch |
                        |------|--------|--------|-------|--------|-------|
                        |  è½»é‡åŒ– | 256 | 4 | 4 | 10 | 16 |
                        |  æ ‡å‡† | 512 | 8 | 8 | 50 | 32 |
                        |  åŸå§‹ | 768 | 12 | 12 | 200 | 64 |
                        
                        **æç¤º**: ä¸‹æ–¹æ‰€æœ‰å‚æ•°éƒ½å¯ä»¥è‡ªç”±è°ƒæ•´ï¼
                        """)
                
                gr.Markdown("###  æ¨¡å‹æ¶æ„å‚æ•°")
                
                with gr.Row():
                    with gr.Column():
                        hidden_size = gr.Slider(
                            minimum=128, maximum=1024, value=512, step=64,
                            label="éšè—å±‚ç»´åº¦ (Hidden Size)",
                            info="è½»é‡:256 | æ ‡å‡†:512 | åŸå§‹:768"
                        )
                        num_layers = gr.Slider(
                            minimum=2, maximum=24, value=8, step=1,
                            label="Transformerå±‚æ•° (Num Layers)",
                            info="è½»é‡:4 | æ ‡å‡†:8 | åŸå§‹:12"
                        )
                        num_heads = gr.Slider(
                            minimum=2, maximum=16, value=8, step=1,
                            label="æ³¨æ„åŠ›å¤´æ•° (Attention Heads)",
                            info="è½»é‡:4 | æ ‡å‡†:8 | åŸå§‹:12"
                        )
                    
                    with gr.Column():
                        intermediate_size = gr.Slider(
                            minimum=512, maximum=4096, value=2048, step=256,
                            label="FFNä¸­é—´å±‚ç»´åº¦ (Intermediate Size)",
                            info="è½»é‡:1024 | æ ‡å‡†:2048 | åŸå§‹:3072"
                        )
                        max_position = gr.Slider(
                            minimum=512, maximum=8192, value=4096, step=512,
                            label="æœ€å¤§åºåˆ—é•¿åº¦ (Max Position)",
                            info="è½»é‡:2048 | æ ‡å‡†:4096 | åŸå§‹:4096"
                        )
                
                gr.Markdown("###  è®­ç»ƒå‚æ•°")
                
                with gr.Row():
                    with gr.Column():
                        epochs = gr.Slider(
                            minimum=1, maximum=500, value=50, step=1,
                            label="è®­ç»ƒè½®æ•° (Epochs)",
                            info="è½»é‡:10 | æ ‡å‡†:50 | åŸå§‹:200"
                        )
                        batch_size = gr.Slider(
                            minimum=8, maximum=256, value=32, step=8,
                            label="æ‰¹å¤§å° (Batch Size)",
                            info="è½»é‡:16 | æ ‡å‡†:32 | åŸå§‹:64"
                        )
                        learning_rate = gr.Slider(
                            minimum=1e-5, maximum=1e-2, value=1e-4, step=1e-5,
                            label="å­¦ä¹ ç‡ (Learning Rate)",
                            info="é€šç”¨: 1e-4 | èŒƒå›´: 1e-5 ~ 1e-2"
                        )
                    
                    with gr.Column():
                        data_file = gr.File(
                            label=" ä¸Šä¼ CSIæ•°æ®æ–‡ä»¶ (.npy æˆ– .mat)",
                            file_count="single",
                            type="filepath"
                        )
                        gr.Markdown("""
                        ### æ•°æ®æ ¼å¼è¦æ±‚
                        
                        - **æ ¼å¼**: .npy æˆ– .mat æ–‡ä»¶
                        - **ç»´åº¦**: (æ ·æœ¬æ•°, å¤©çº¿æ•°, å­è½½æ³¢æ•°, 2)
                        - **ç¤ºä¾‹**: (1000, 32, 64, 2)
                        
                        å¦‚ä¸ä¸Šä¼ æ–‡ä»¶ï¼Œä½¿ç”¨å†…ç½®æ•°æ®é›†
                        """)
                
                with gr.Row():
                    custom_train_btn = gr.Button(" å¼€å§‹è®­ç»ƒ", scale=2, variant="primary")
                    custom_stop_btn = gr.Button(" åœæ­¢è®­ç»ƒ", scale=1, variant="stop")
                
                custom_status = gr.Textbox(
                    label=" è®­ç»ƒçŠ¶æ€",
                    interactive=False,
                    lines=15,
                    max_lines=30
                )
                
                def apply_preset(preset_name):
                    """æ ¹æ®é¢„è®¾è¿”å›æ‰€æœ‰å‚æ•°"""
                    presets = {
                        "è½»é‡åŒ–é…ç½®": (256, 4, 4, 1024, 2048, 10, 16, 1e-4),
                        "æ ‡å‡†é…ç½®": (512, 8, 8, 2048, 4096, 50, 32, 1e-4),
                        "åŸå§‹é…ç½®": (768, 12, 12, 3072, 4096, 200, 64, 1e-4)
                    }
                    return presets.get(preset_name, (512, 8, 8, 2048, 4096, 50, 32, 1e-4))
                
                preset.change(
                    fn=lambda p: apply_preset(p),
                    inputs=preset,
                    outputs=[hidden_size, num_layers, num_heads, intermediate_size, max_position, epochs, batch_size, learning_rate]
                )
                
                custom_train_btn.click(
                    fn=manager.train_model,
                    inputs=[hidden_size, num_layers, num_heads, intermediate_size, max_position, epochs, batch_size, learning_rate],
                    outputs=custom_status
                )
                
                custom_stop_btn.click(
                    fn=manager.stop_training,
                    outputs=custom_status
                )
            
            # æ ‡ç­¾3: ç”Ÿæˆæ•°æ®
            with gr.TabItem(" ç”Ÿæˆæ•°æ®"):
                gr.Markdown("## CSIæ•°æ®ç”Ÿæˆå·¥å…·ï¼ˆMassive MIMO 5G NRï¼‰")
                
                gr.Markdown("###  åŸºæœ¬å‚æ•°")
                with gr.Row():
                    with gr.Column():
                        num_cells = gr.Slider(
                            minimum=1, maximum=50, value=10, step=1,
                            label="åŸºç«™æ•°é‡ (Num Cells)",
                            info="é»˜è®¤: 10 | èŒƒå›´: 1-50"
                        )
                        num_ues = gr.Slider(
                            minimum=10, maximum=500, value=200, step=10,
                            label="æ¯å°åŒºç”¨æˆ·æ•° (UEs per Cell)",
                            info="é»˜è®¤: 200 | èŒƒå›´: 10-500"
                        )
                        num_subcarriers = gr.Slider(
                            minimum=12, maximum=1024, value=64, step=12,
                            label="å­è½½æ³¢æ•° (Num Subcarriers)",
                            info="é»˜è®¤: 64 | 5G NR: 12/24/48/64/128/256/512/1024"
                        )
                    
                    with gr.Column():
                        massive_mimo_antennas = gr.Slider(
                            minimum=8, maximum=256, value=64, step=8,
                            label="åŸºç«™å¤©çº¿æ•° (BS Antennas - Massive MIMO)",
                            info="é»˜è®¤: 64 | èŒƒå›´: 8-256"
                        )
                        num_receive_antennas = gr.Slider(
                            minimum=1, maximum=16, value=4, step=1,
                            label="ç”¨æˆ·ç«¯å¤©çº¿æ•° (UE Antennas)",
                            info="é»˜è®¤: 4 | èŒƒå›´: 1-16"
                        )
                
                gr.Markdown("###  ä¿¡é“å‚æ•°")
                with gr.Row():
                    with gr.Column():
                        nr_sample_rate = gr.Slider(
                            minimum=1e6, maximum=100e6, value=30.72e6, step=1e6,
                            label="5G NR é‡‡æ ·ç‡ (Sample Rate, Hz)",
                            info="é»˜è®¤: 30.72 MHz | èŒƒå›´: 1-100 MHz"
                        )
                        snr_nr = gr.Slider(
                            minimum=0, maximum=40, value=25, step=1,
                            label="ä¿¡å™ªæ¯” (SNR, dB)",
                            info="é»˜è®¤: 25 dB | èŒƒå›´: 0-40 dB"
                        )
                    
                    with gr.Column():
                        speed_high = gr.Slider(
                            minimum=0, maximum=500, value=120, step=10,
                            label="é«˜é€Ÿåœºæ™¯ç”¨æˆ·é€Ÿåº¦ (Speed, km/h)",
                            info="é»˜è®¤: 120 km/h | èŒƒå›´: 0-500 km/h"
                        )
                        carrier_freq = gr.Slider(
                            minimum=0.7e9, maximum=100e9, value=3.5e9, step=0.1e9,
                            label="è½½æ³¢é¢‘ç‡ (Carrier Frequency, Hz)",
                            info="é»˜è®¤: 3.5 GHz | 5G NR: 0.7-100 GHz"
                        )
                
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("""
                        ###  ç”Ÿæˆè¯´æ˜
                        
                        **æ•°æ®ç»“æ„**: 
                        - å¤šå°åŒºã€å¤šç”¨æˆ·ã€å¤šåœºæ™¯
                        - 3ç§åœºæ™¯: é™æ­¢ã€é«˜é€Ÿã€åŸå¸‚å®å°åŒº
                        - ç»´åº¦: (åŸºç«™æ•° Ã— ç”¨æˆ·æ•° Ã— åœºæ™¯æ•°)
                        
                        **æ–‡ä»¶è¾“å‡º**: 
                        `foundation_model_data/csi_data_massive_mimo.mat`
                        
                        **é¢„è®¡æ—¶é—´**: å–å†³äºå‚æ•°è§„æ¨¡
                        - é»˜è®¤é…ç½®(10Ã—200): ~5-10åˆ†é’Ÿ
                        - å¤§è§„æ¨¡(50Ã—500): ~30-60åˆ†é’Ÿ
                        """)
                    
                    with gr.Column():
                        gr.Markdown("""
                        ###  å‚æ•°å»ºè®®
                        
                        **å¿«é€Ÿæµ‹è¯•**:
                        - åŸºç«™: 2, ç”¨æˆ·: 20
                        
                        **æ ‡å‡†è®­ç»ƒ**:
                        - åŸºç«™: 10, ç”¨æˆ·: 200
                        
                        **å¤§è§„æ¨¡æ•°æ®é›†**:
                        - åŸºç«™: 50, ç”¨æˆ·: 500
                        
                        **æ³¨æ„**: MATLABéœ€è¦å®‰è£…
                        - Communications Toolbox
                        - 5G Toolbox (æ¨è)
                        """)
                
                gen_btn = gr.Button(" ç”Ÿæˆæ•°æ®", variant="primary", size="lg")
                gen_status = gr.Textbox(
                    label="ç”ŸæˆçŠ¶æ€",
                    interactive=False,
                    lines=10
                )
                
                def generate_data(cells, ues, subcarriers, bs_antennas, ue_antennas, sample_rate, snr, speed, freq):
                    """ç”ŸæˆCSIæ•°æ®ï¼ˆè°ƒç”¨MATLABè„šæœ¬ï¼‰"""
                    try:
                        return f""" æ­£åœ¨å‡†å¤‡ç”Ÿæˆæ•°æ®...
                        
 æ•°æ®ç”Ÿæˆå‚æ•°:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
åŸºæœ¬å‚æ•°:
  â€¢ åŸºç«™æ•°é‡: {int(cells)}
  â€¢ æ¯å°åŒºç”¨æˆ·æ•°: {int(ues)}
  â€¢ å­è½½æ³¢æ•°: {int(subcarriers)}

å¤©çº¿é…ç½®:
  â€¢ åŸºç«™å¤©çº¿æ•° (Massive MIMO): {int(bs_antennas)}
  â€¢ ç”¨æˆ·ç«¯å¤©çº¿æ•°: {int(ue_antennas)}

ä¿¡é“å‚æ•°:
  â€¢ é‡‡æ ·ç‡: {sample_rate/1e6:.2f} MHz
  â€¢ ä¿¡å™ªæ¯”: {snr} dB
  â€¢ é«˜é€Ÿç”¨æˆ·é€Ÿåº¦: {speed} km/h
  â€¢ è½½æ³¢é¢‘ç‡: {freq/1e9:.2f} GHz

 é¢„è®¡ç”Ÿæˆæ•°æ®:
  â€¢ æ€»æ ·æœ¬æ•°: {int(cells)} Ã— {int(ues)} Ã— 3åœºæ™¯ = {int(cells * ues * 3)}
  â€¢ æ•°æ®ç»´åº¦: ({int(subcarriers)}, {int(bs_antennas)}, {int(ue_antennas)})
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

 æ³¨æ„: æ­¤åŠŸèƒ½éœ€è¦ MATLAB å’Œç›¸å…³å·¥å…·ç®±

 æ‰‹åŠ¨æ‰§è¡Œæ­¥éª¤:
1. æ‰“å¼€ MATLAB
2. ä¿®æ”¹ data_generator.m ä¸­çš„å‚æ•°:
   numCells = {int(cells)};
   numUEs = {int(ues)};
   numSubcarriers = {int(subcarriers)};
   massiveMIMONumAntennas = {int(bs_antennas)};
   numReceiveAntennas = {int(ue_antennas)};
   nrSampleRate = {sample_rate};
   snrNR = {snr};
   speedHigh = {speed};
   fc = {freq};

3. è¿è¡Œ: run('data_generator.m')
4. ç­‰å¾…ç”Ÿæˆå®Œæˆ

 æˆ–ä½¿ç”¨å‘½ä»¤è¡Œ:
   matlab -batch "run('data_generator.m')"

 ç”Ÿæˆæ–‡ä»¶å°†ä¿å­˜åˆ°:
   foundation_model_data/csi_data_massive_mimo.mat
"""
                    except Exception as e:
                        return f" ç”Ÿæˆé”™è¯¯: {str(e)}"
                
                gen_btn.click(
                    fn=generate_data,
                    inputs=[num_cells, num_ues, num_subcarriers, massive_mimo_antennas, num_receive_antennas, 
                            nr_sample_rate, snr_nr, speed_high, carrier_freq],
                    outputs=gen_status
                )
            
            # æ ‡ç­¾4: è¿›è¡Œå®éªŒ
            with gr.TabItem(" è¿›è¡Œå®éªŒ"):
                gr.Markdown("## å®éªŒä¸éªŒè¯")
                
                # æ¨¡å‹é€‰æ‹©å’ŒçŠ¶æ€
                with gr.Row():
                    with gr.Column(scale=2):
                        model_selector = gr.Dropdown(
                            choices=manager.get_model_list_display(),
                            label=" é€‰æ‹©æ¨¡å‹",
                            value=manager.get_model_list_display()[0] if manager.get_model_list_display() else None,
                            info="é€‰æ‹©è¦ç”¨äºå®éªŒçš„æ¨¡å‹æ–‡ä»¶"
                        )
                        
                        with gr.Row():
                            load_model_btn = gr.Button("ğŸ“¥ åŠ è½½é€‰ä¸­æ¨¡å‹", variant="secondary", size="sm")
                            rescan_models_btn = gr.Button(" é‡æ–°æ‰«æ", size="sm")
                    
                    with gr.Column(scale=3):
                        model_status_display = gr.Textbox(
                            label=" å½“å‰æ¨¡å‹çŠ¶æ€",
                            value=manager.get_model_status(),
                            interactive=False,
                            lines=4
                        )
                
                # æ¨¡å‹æ“ä½œå‡½æ•°
                def load_selected_model(model_name):
                    result = manager.load_model_by_name(model_name)
                    return result, manager.get_model_status()
                
                def rescan_models():
                    manager.available_models = manager.scan_available_models()
                    model_list = manager.get_model_list_display()
                    return gr.update(choices=model_list, value=model_list[0] if model_list else None), manager.get_model_status()
                
                load_model_btn.click(
                    fn=load_selected_model,
                    inputs=model_selector,
                    outputs=[model_status_display, model_status_display]
                )
                
                rescan_models_btn.click(
                    fn=rescan_models,
                    outputs=[model_selector, model_status_display]
                )
                
                gr.Markdown("---")
                
                # å®éªŒç±»å‹é€‰æ‹©
                experiment_category = gr.Radio(
                    choices=["åŸºç¡€å®éªŒ", "é«˜çº§å®éªŒ", "å…¨éƒ¨å®éªŒ"],
                    value="åŸºç¡€å®éªŒ",
                    label="å®éªŒåˆ†ç±»"
                )
                
                # åŸºç¡€å®éªŒ
                with gr.Column(visible=True) as basic_exp_col:
                    gr.Markdown("### ğŸ”° åŸºç¡€å®éªŒ - æ¨¡å‹æ€§èƒ½éªŒè¯")
                    
                    with gr.Row():
                        basic_exp_type = gr.Dropdown(
                            choices=[
                                "Reconstruction Error - é‡æ„è¯¯å·®",
                                "Prediction Accuracy - é¢„æµ‹å‡†ç¡®åº¦",
                                "SNR Robustness - SNRé²æ£’æ€§",
                                "Compression Ratio - å‹ç¼©ç‡",
                                "Inference Speed - æ¨ç†é€Ÿåº¦",
                                "All Basic Tests - è¿è¡Œæ‰€æœ‰åŸºç¡€å®éªŒ"
                            ],
                            label="é€‰æ‹©åŸºç¡€å®éªŒ",
                            value="Reconstruction Error - é‡æ„è¯¯å·®"
                        )
                        run_basic_exp_btn = gr.Button(" è¿è¡ŒåŸºç¡€å®éªŒ", variant="primary", size="lg")
                    
                    basic_exp_output = gr.Textbox(
                        label="åŸºç¡€å®éªŒç»“æœ",
                        interactive=False,
                        lines=12
                    )
                
                # é«˜çº§å®éªŒ
                with gr.Column(visible=False) as advanced_exp_col:
                    gr.Markdown("### ğŸ”¬ é«˜çº§å®éªŒ - æ·±åº¦åˆ†æ")
                    
                    with gr.Row():
                        advanced_exp_type = gr.Dropdown(
                            choices=[
                                "Masking Ratio Sensitivity - æ©ç æ¯”ç‡æ•æ„Ÿæ€§åˆ†æ",
                                "Error Distribution - è¯¯å·®åˆ†å¸ƒåˆ†æ",
                                "Prediction Horizon - é¢„æµ‹æ­¥é•¿åˆ†æ",
                                "Baseline Comparison - åŸºçº¿æ–¹æ³•å¯¹æ¯”",
                                "Attention Visualization - æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–",
                                "All Advanced Experiments - è¿è¡Œæ‰€æœ‰é«˜çº§å®éªŒ"
                            ],
                            label="é€‰æ‹©é«˜çº§å®éªŒ",
                            value="Masking Ratio Sensitivity - æ©ç æ¯”ç‡æ•æ„Ÿæ€§åˆ†æ"
                        )
                        run_advanced_exp_btn = gr.Button("ğŸ”¬ è¿è¡Œé«˜çº§å®éªŒ", variant="primary", size="lg")
                    
                    advanced_exp_output = gr.Textbox(
                        label="é«˜çº§å®éªŒç»“æœ",
                        interactive=False,
                        lines=12
                    )
                
                # å…¨éƒ¨å®éªŒ
                with gr.Column(visible=False) as all_exp_col:
                    gr.Markdown("### ğŸš€ å®Œæ•´å®éªŒå¥—ä»¶ - åŸºç¡€æµ‹è¯• + é«˜çº§å®éªŒ")
                    gr.Markdown("""
                    è¿è¡Œæ‰€æœ‰10é¡¹æµ‹è¯•å’Œå®éªŒï¼Œç”Ÿæˆå®Œæ•´çš„æ€§èƒ½è¯„ä¼°æŠ¥å‘Šï¼š
                    
                    **åŸºç¡€æµ‹è¯• (5é¡¹)**:
                    - é‡æ„è¯¯å·®åˆ†æ
                    - é¢„æµ‹å‡†ç¡®åº¦è¯„ä¼°
                    - SNRé²æ£’æ€§æµ‹è¯•
                    - å‹ç¼©è´¨é‡åˆ†æ
                    - æ¨ç†é€Ÿåº¦æµ‹è¯•
                    
                    **é«˜çº§å®éªŒ (5é¡¹)**:
                    - æ©ç æ¯”ç‡æ•æ„Ÿæ€§åˆ†æ (æµ‹è¯•15ç§æ©ç æ¯”ç‡)
                    - è¯¯å·®åˆ†å¸ƒåˆ†æ (ç›´æ–¹å›¾ã€ç®±çº¿å›¾ã€Q-Qå›¾)
                    - é¢„æµ‹æ­¥é•¿åˆ†æ (æµ‹è¯•1-20æ­¥é¢„æµ‹èƒ½åŠ›)
                    - åŸºçº¿æ–¹æ³•å¯¹æ¯” (é›¶å¡«å……ã€å‡å€¼å¡«å……)
                    - æ³¨æ„åŠ›æƒé‡å¯è§†åŒ– (çƒ­åŠ›å›¾)
                    """)
                    
                    with gr.Row():
                        run_all_exp_btn = gr.Button(" è¿è¡Œå…¨éƒ¨å®éªŒ", variant="primary", size="lg")
                    
                    all_exp_output = gr.Textbox(
                        label="å…¨éƒ¨å®éªŒè¿›åº¦",
                        interactive=False,
                        lines=15
                    )
                
                # åˆ‡æ¢å®éªŒç±»å‹
                def toggle_experiment_type(category):
                    if category == "åŸºç¡€å®éªŒ":
                        return gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)
                    elif category == "é«˜çº§å®éªŒ":
                        return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)
                    else:  # å…¨éƒ¨å®éªŒ
                        return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True)
                
                experiment_category.change(
                    fn=toggle_experiment_type,
                    inputs=experiment_category,
                    outputs=[basic_exp_col, advanced_exp_col, all_exp_col]
                )
                
                # åŸºç¡€å®éªŒæ‰§è¡Œ
                # åŸºç¡€å®éªŒæ‰§è¡Œ
                def run_basic_experiment(exp_type):
                    if manager.model is None:
                        # é‡æ–°æ‰«æå¹¶å°è¯•åŠ è½½æ¨¡å‹
                        manager.available_models = manager.scan_available_models()
                        if manager.available_models:
                            manager.auto_load_model(manager.available_models[0])
                        
                        if manager.model is None:
                            return " æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹ï¼\n\n è§£å†³æ–¹æ¡ˆï¼š\n1. è¯·å…ˆåœ¨'ä¸€é”®è®­ç»ƒ'æˆ–'å¯¼å…¥æ•°æ®è®­ç»ƒ'ä¸­è®­ç»ƒæ¨¡å‹\n2. æˆ–å°†å·²è®­ç»ƒæ¨¡å‹æ”¾å…¥ checkpoints/ ç›®å½•\n3. ç‚¹å‡»'é‡æ–°æ‰«æ'åˆ·æ–°æ¨¡å‹åˆ—è¡¨"
                    
                    try:
                        # æ£€æŸ¥æ˜¯å¦è¿è¡Œæ‰€æœ‰åŸºç¡€å®éªŒ
                        if "All Basic Tests" in exp_type:
                            exp_list = [
                                "Reconstruction Error - é‡æ„è¯¯å·®",
                                "Prediction Accuracy - é¢„æµ‹å‡†ç¡®åº¦",
                                "SNR Robustness - SNRé²æ£’æ€§",
                                "Compression Ratio - å‹ç¼©ç‡",
                                "Inference Speed - æ¨ç†é€Ÿåº¦"
                            ]
                            return manager.run_experiments(exp_list)
                        
                        # å•ä¸ªå®éªŒ
                        return manager.run_experiments([exp_type])
                        
                    except Exception as e:
                        return f" å®éªŒé”™è¯¯: {str(e)}"
                
                run_basic_exp_btn.click(
                    fn=run_basic_experiment,
                    inputs=basic_exp_type,
                    outputs=basic_exp_output
                )
                
                # é«˜çº§å®éªŒæ‰§è¡Œ
                def run_advanced_experiment(exp_type):
                    if manager.model is None:
                        # é‡æ–°æ‰«æå¹¶å°è¯•åŠ è½½æ¨¡å‹
                        manager.available_models = manager.scan_available_models()
                        if manager.available_models:
                            manager.auto_load_model(manager.available_models[0])
                        
                        if manager.model is None:
                            return " æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹ï¼\n\n è§£å†³æ–¹æ¡ˆï¼š\n1. è¯·å…ˆåœ¨'ä¸€é”®è®­ç»ƒ'æˆ–'å¯¼å…¥æ•°æ®è®­ç»ƒ'ä¸­è®­ç»ƒæ¨¡å‹\n2. æˆ–å°†å·²è®­ç»ƒæ¨¡å‹æ”¾å…¥ checkpoints/ ç›®å½•\n3. ç‚¹å‡»'é‡æ–°æ‰«æ'åˆ·æ–°æ¨¡å‹åˆ—è¡¨"
                    
                    try:
                        # æ£€æŸ¥æ˜¯å¦è¿è¡Œæ‰€æœ‰é«˜çº§å®éªŒ
                        if "All Advanced Experiments" in exp_type:
                            exp_list = [
                                "Masking Ratio Sensitivity - æ©ç æ¯”ç‡æ•æ„Ÿæ€§",
                                "Scenario Performance - åœºæ™¯æ€§èƒ½åˆ†æ",
                                "Subcarrier Performance - å­è½½æ³¢æ€§èƒ½",
                                "Doppler Robustness - å¤šæ™®å‹’é²æ£’æ€§",
                                "Cross-scenario Generalization - è·¨åœºæ™¯æ³›åŒ–",
                                "Baseline Comparison - åŸºçº¿å¯¹æ¯”",
                                "Error Distribution - é”™è¯¯åˆ†å¸ƒ",
                                "Attention Visualization - æ³¨æ„åŠ›å¯è§†åŒ–"
                            ]
                            return manager.run_experiments(exp_list)
                        
                        # å•ä¸ªå®éªŒ
                        return manager.run_experiments([exp_type])
                        
                    except Exception as e:
                        return f" å®éªŒé”™è¯¯: {str(e)}"
                
                run_advanced_exp_btn.click(
                    fn=run_advanced_experiment,
                    inputs=advanced_exp_type,
                    outputs=advanced_exp_output
                )
                
                # å…¨éƒ¨å®éªŒæ‰§è¡Œ
                def run_all_experiments():
                    if manager.model is None:
                        # é‡æ–°æ‰«æå¹¶å°è¯•åŠ è½½æ¨¡å‹
                        manager.available_models = manager.scan_available_models()
                        if manager.available_models:
                            manager.auto_load_model(manager.available_models[0])
                        
                        if manager.model is None:
                            return " æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹ï¼\n\n è§£å†³æ–¹æ¡ˆï¼š\n1. è¯·å…ˆåœ¨'ä¸€é”®è®­ç»ƒ'æˆ–'å¯¼å…¥æ•°æ®è®­ç»ƒ'ä¸­è®­ç»ƒæ¨¡å‹\n2. æˆ–å°†å·²è®­ç»ƒæ¨¡å‹æ”¾å…¥ checkpoints/ ç›®å½•\n3. ç‚¹å‡»'é‡æ–°æ‰«æ'åˆ·æ–°æ¨¡å‹åˆ—è¡¨"
                    
                    try:
                        # æ‰€æœ‰å®éªŒåˆ—è¡¨
                        all_exp_list = [
                            "Reconstruction Error - é‡æ„è¯¯å·®",
                            "Prediction Accuracy - é¢„æµ‹å‡†ç¡®åº¦",
                            "SNR Robustness - SNRé²æ£’æ€§",
                            "Compression Ratio - å‹ç¼©ç‡",
                            "Inference Speed - æ¨ç†é€Ÿåº¦",
                            "Masking Ratio Sensitivity - æ©ç æ¯”ç‡æ•æ„Ÿæ€§",
                            "Scenario Performance - åœºæ™¯æ€§èƒ½åˆ†æ",
                            "Subcarrier Performance - å­è½½æ³¢æ€§èƒ½",
                            "Doppler Robustness - å¤šæ™®å‹’é²æ£’æ€§",
                            "Cross-scenario Generalization - è·¨åœºæ™¯æ³›åŒ–",
                            "Baseline Comparison - åŸºçº¿å¯¹æ¯”",
                            "Error Distribution - é”™è¯¯åˆ†å¸ƒ",
                            "Attention Visualization - æ³¨æ„åŠ›å¯è§†åŒ–"
                        ]
                        return manager.run_experiments(all_exp_list)
                        
                    except Exception as e:
                        return f" å®éªŒé”™è¯¯: {str(e)}"
                
                run_all_exp_btn.click(
                    fn=run_all_experiments,
                    outputs=all_exp_output
                )
            
            # æ ‡ç­¾5: å…³äº
            with gr.TabItem(" å…³äº"):
                gr.Markdown("""
                ## ğŸš€ CSIBERT é¡¹ç›®ä¿¡æ¯
                
                **é¡¹ç›®åç§°**: BERT4MIMO - AI for Wireless Communications
                
                **ç‰ˆæœ¬**: 2.0.0 (é‡æ„ç‰ˆ)
                
                **4å¤§åŠŸèƒ½**:
                1. **ğŸ¯ ä¸€é”®è®­ç»ƒ** - ä»æ•°æ®ç”Ÿæˆåˆ°è®­ç»ƒæµ‹è¯•çš„å…¨è‡ªåŠ¨æµç¨‹ï¼Œæ”¯æŒå‚æ•°è‡ªå®šä¹‰
                2. **ğŸ“¥ å¯¼å…¥æ•°æ®è®­ç»ƒ** - å¯¼å…¥ç°æœ‰æ•°æ®ï¼Œé€‰æ‹©é…ç½®æ–¹æ¡ˆæˆ–è‡ªå®šä¹‰å‚æ•°
                3. **ğŸ”§ ç”Ÿæˆæ•°æ®** - ç”ŸæˆåˆæˆCSIæ•°æ®é›†ï¼Œæ”¯æŒ9ç§å‚æ•°é…ç½®
                4. **ğŸ§ª è¿›è¡Œå®éªŒ** - 5ç§åŸºç¡€å®éªŒ + 5ç§é«˜çº§å®éªŒï¼Œæ”¯æŒå•é¡¹/æ‰¹é‡/å…¨éƒ¨è¿è¡Œ
                
                ---
                
                ## ğŸ§ª å®éªŒåŠŸèƒ½è¯´æ˜
                
                **æ™ºèƒ½å®éªŒç®¡ç†**:
                - âœ“ è‡ªåŠ¨æ£€æµ‹å·²è®­ç»ƒæ¨¡å‹ï¼Œæ— éœ€é‡å¤è®­ç»ƒ
                - âœ“ æ”¯æŒå•é¡¹å®éªŒã€æ‰¹é‡è¿è¡Œã€å…¨éƒ¨è¿è¡Œ
                - âœ“ è‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å’Œåˆ†ææŠ¥å‘Š
                - âœ“ ç»“æœä¿å­˜åˆ° validation_results/ å’Œ advanced_experiments/ ç›®å½•
                
                **åŸºç¡€å®éªŒ** (å¿«é€Ÿæ€§èƒ½éªŒè¯):
                1. é‡æ„è¯¯å·® - MSE/NMSE/MAEåˆ†æ
                2. é¢„æµ‹å‡†ç¡®åº¦ - æ—¶åºé¢„æµ‹èƒ½åŠ› (1/3/5/10æ­¥)
                3. SNRé²æ£’æ€§ - æŠ—å™ªå£°æ€§èƒ½ (-10~30dB)
                4. å‹ç¼©è´¨é‡ - æ•°æ®å‹ç¼©æ•ˆç‡ (10x~50x)
                5. æ¨ç†é€Ÿåº¦ - è®¡ç®—æ€§èƒ½æµ‹è¯•
                
                **é«˜çº§å®éªŒ** (æ·±åº¦æ€§èƒ½åˆ†æ):
                1. æ©ç æ¯”ç‡æ•æ„Ÿæ€§ - æµ‹è¯•15ç§æ©ç æ¯”ç‡ (0-70%)
                2. è¯¯å·®åˆ†å¸ƒåˆ†æ - ç›´æ–¹å›¾ã€ç®±çº¿å›¾ã€Q-Qå›¾
                3. é¢„æµ‹æ­¥é•¿åˆ†æ - æµ‹è¯•1-20æ­¥é¢„æµ‹èƒ½åŠ›
                4. åŸºçº¿æ–¹æ³•å¯¹æ¯” - ä¸é›¶å¡«å……ã€å‡å€¼å¡«å……æ¯”è¾ƒ
                5. æ³¨æ„åŠ›æƒé‡å¯è§†åŒ– - æ¨¡å‹æ³¨æ„åŠ›çƒ­åŠ›å›¾
                
                ---
                
                ## âš™ï¸ ä¸‰çº§é…ç½®æ–¹æ¡ˆ
                
                ### æ–¹æ¡ˆ1ï¼šè½»é‡åŒ–é…ç½® âš¡
                - **åœºæ™¯**: å¿«é€Ÿä½“éªŒã€å­¦ä¹ ã€åŸå‹éªŒè¯
                - **ç¡¬ä»¶**: 4GB æ˜¾å­˜ï¼ˆå…¥é—¨çº§æ˜¾å¡ï¼‰
                - **æ¨¡å‹**: Hidden=256, Layers=4, Heads=4
                - **è®­ç»ƒ**: Epochs=10, Batch=16, è€—æ—¶â‰ˆ5åˆ†é’Ÿ
                - **ç²¾åº¦**: 85% | **é€Ÿåº¦**: 100 fps | **æ˜¾å­˜**: 2GB
                
                ### æ–¹æ¡ˆ2ï¼šæ ‡å‡†é…ç½® ğŸ¯ï¼ˆæ¨èï¼‰
                - **åœºæ™¯**: ç”Ÿäº§ç¯å¢ƒã€åº”ç”¨å¼€å‘ã€å¸¸è§„ç ”ç©¶
                - **ç¡¬ä»¶**: 4-8GB æ˜¾å­˜ï¼ˆä¸»æµæ˜¾å¡ï¼‰
                - **æ¨¡å‹**: Hidden=512, Layers=8, Heads=8
                - **è®­ç»ƒ**: Epochs=50, Batch=32, è€—æ—¶â‰ˆ25åˆ†é’Ÿ
                - **ç²¾åº¦**: 92% | **é€Ÿåº¦**: 50 fps | **æ˜¾å­˜**: 4GB
                
                ### æ–¹æ¡ˆ3ï¼šåŸå§‹é…ç½® 
                - **åœºæ™¯**: è®ºæ–‡å‘è¡¨ã€é«˜ç²¾åº¦è¦æ±‚ã€ç¦»çº¿å¤„ç†
                - **ç¡¬ä»¶**: 8GB+ æ˜¾å­˜ï¼ˆé«˜ç«¯æ˜¾å¡ï¼‰
                - **æ¨¡å‹**: Hidden=768, Layers=12, Heads=12
                - **è®­ç»ƒ**: Epochs=200, Batch=64, è€—æ—¶â‰ˆ150åˆ†é’Ÿ
                - **ç²¾åº¦**: 95% | **é€Ÿåº¦**: 20 fps | **æ˜¾å­˜**: 8GB
                
                ---
                
                ##  ç¡¬ä»¶æ¨è
                
                | æ˜¾å¡å‹å· | æ˜¾å­˜ | æ¨èé…ç½® |
                |---------|------|--------|
                | GTX 1650/1660 | 4GB |  è½»é‡åŒ– |
                | RTX 2060/2080 | 4-6GB |  æ ‡å‡† |
                | RTX 3060/3070 | 6-8GB |  æ ‡å‡† |
                | RTX 3080/3090 | 10-24GB |  åŸå§‹ |
                | RTX 4080/4090 | 12-24GB |  åŸå§‹ |
                
                ---
                
                ##  ä¸»è¦ç‰¹æ€§
                
                -  BERT Transformer æ¶æ„
                -  å¤§è§„æ¨¡ MIMO æ”¯æŒ
                -  CSI å‹ç¼©å’Œé¢„æµ‹
                -  ä¸‰çº§çµæ´»é…ç½®
                -  å®Œæ•´éªŒè¯å¥—ä»¶ï¼ˆ13ä¸ªæµ‹è¯•ï¼‰
                
                **æ ¸å¿ƒæ¨¡å—**:
                - `model.py` - CSIBERT æ¨¡å‹å®šä¹‰
                - `train.py` - è®­ç»ƒè„šæœ¬
                - `experiments_extended.py` - é«˜çº§å®éªŒ
                - `model_validation.py` - éªŒè¯å·¥å…·
                
                **è¾“å‡ºç›®å½•**:
                - `checkpoints/` - æ¨¡å‹æ£€æŸ¥ç‚¹
                - `imgs/` - å®éªŒå¯è§†åŒ–ç»“æœ
                - `foundation_model_data/` - CSI æ•°æ®é›†
                
                ---
                
                ## ğŸ“– æ–‡æ¡£å¯¼èˆª
                
                æ›´è¯¦ç»†çš„ä¿¡æ¯è¯·æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£ï¼š
                - **USAGE.md** - è¯¦ç»†çš„ä½¿ç”¨æŒ‡å—å’Œé…ç½®é€‰æ‹©
                - **README.md** - é¡¹ç›®æ¦‚è§ˆ
                - **FILES.md** - æ–‡ä»¶ç»“æ„è¯´æ˜
                - **TESTS.md** - æµ‹è¯•å’Œå®éªŒæ–¹æ³•
                
                ** å¿«é€Ÿé“¾æ¥**:
                - GitHub: https://github.com/hsms4710-pixel/AI_TeleProject
                """)
    
    return app


if __name__ == "__main__":
    app = create_interface()
    
    print("=" * 60)
    print(" CSIBERT WebUI å¯åŠ¨")
    print("=" * 60)
    print("ğŸ“ è®¿é—®åœ°å€: http://127.0.0.1:7861")
    print("  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
    print("=" * 60)
    
    app.launch(
        server_name="127.0.0.1",
        server_port=7861,
        share=False,
        show_api=False
    )

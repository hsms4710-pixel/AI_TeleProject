#!/usr/bin/env python3
"""
CSIBERT é«˜çº§å®éªŒæ¨¡å—

æœ¬æ¨¡å—æä¾›é«˜çº§éªŒè¯åŠŸèƒ½:
1. Masking ratio sensitivity analysis
2. Scenario-wise performance evaluation
3. Subcarrier performance analysis
4. Doppler robustness testing
5. Cross-scenario generalization
6. Baseline comparison
7. Attention mechanism visualization
8. Error distribution analysis
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
from sklearn.neural_network import MLPRegressor
from tqdm import tqdm
import pandas as pd
import seaborn as sns
import os


class AdvancedCSIBERTExperiments:
    """é«˜çº§ CSIBERT å®éªŒå¥—ä»¶"""
    
    def __init__(self, model, padded_data, masked_data, feature_dim, device, 
                 attention_masks=None, output_dir='imgs'):
        """
        åˆå§‹åŒ–å®éªŒæ¨¡å—
        
        Args:
            model: å·²åŠ è½½çš„ CSIBERT æ¨¡å‹
            padded_data: å¡«å……åçš„ CSI æ•°æ® (N, T, F)
            masked_data: æ©ç åçš„æ•°æ® (N, T, F) 
            feature_dim: ç‰¹å¾ç»´åº¦
            device: è®¡ç®—è®¾å¤‡
            attention_masks: æ³¨æ„åŠ›æ©ç  (å¯é€‰)
            output_dir: è¾“å‡ºç›®å½•
        """
        self.model = model
        self.padded_data = padded_data
        self.masked_data = masked_data
        self.feature_dim = feature_dim
        self.device = device
        self.attention_masks = attention_masks
        self.output_dir = output_dir
        
        os.makedirs(output_dir, exist_ok=True)
        
        # è®¾ç½®ç»˜å›¾é£æ ¼
        sns.set_style("ticks")
        plt.rcParams['figure.figsize'] = (12, 6)
    
    def _mask_data(self, data, mask_ratio=0.15):
        """å¯¹æ•°æ®åº”ç”¨æ©ç """
        mask = np.random.rand(*data.shape[:-1]) < mask_ratio
        masked_data = np.copy(data)
        masked_data[mask, :] = 0
        return masked_data, mask
    
    # ======================== Experiment 3: æ©ç æ¯”ç‡æ•æ„Ÿæ€§ ========================
    
    def experiment_masking_ratio_sensitivity(self, mask_ratios=None, num_trials=20):
        """
        æµ‹è¯•ä¸åŒæ©ç æ¯”ç‡ä¸‹çš„æ¨¡å‹æ€§èƒ½
        
        Args:
            mask_ratios: æ©ç æ¯”ç‡åˆ—è¡¨
            num_trials: é‡å¤è¯•éªŒæ¬¡æ•°
            
        Returns:
            results_df: åŒ…å«æ‰€æœ‰ç»“æœçš„ DataFrame
        """
        if mask_ratios is None:
            mask_ratios = np.linspace(0.0, 0.5, 30)
        
        print("\nğŸ”¬ Experiment 3: æ©ç æ¯”ç‡æ•æ„Ÿæ€§æµ‹è¯•")
        results = []
        
        for trial in tqdm(range(num_trials), desc="è¯•éªŒè¿›åº¦"):
            for ratio in mask_ratios:
                masked_data, _ = self._mask_data(self.padded_data, mask_ratio=ratio)
                
                dataset = TensorDataset(
                    torch.tensor(masked_data).float(),
                    torch.tensor(self.padded_data).float()
                )
                loader = DataLoader(dataset, batch_size=32)
                
                mse_errors = []
                with torch.no_grad():
                    for inputs, labels in loader:
                        inputs = inputs.to(self.device)
                        labels = labels.to(self.device)
                        outputs = self.model(inputs)
                        mse = mean_squared_error(
                            labels.cpu().numpy().flatten(),
                            outputs.cpu().numpy().flatten()
                        )
                        mse_errors.append(mse)
                
                results.append({
                    'Masking_Ratio': ratio,
                    'MSE': np.mean(mse_errors),
                    'Trial': trial
                })
        
        results_df = pd.DataFrame(results)
        self._plot_masking_ratio_results(results_df)
        
        print(f"âœ… å®Œæˆ: {len(results)}ä¸ªæ•°æ®ç‚¹")
        return results_df
    
    def _plot_masking_ratio_results(self, df):
        """ç»˜åˆ¶æ©ç æ¯”ç‡ç»“æœ"""
        plt.figure(figsize=(12, 6))
        sns.lineplot(data=df, x='Masking_Ratio', y='MSE', errorbar='sd', err_style="band")
        plt.xlabel("Masking Ratio", fontsize=16)
        plt.ylabel("Reconstruction MSE", fontsize=16)
        plt.title("Effect of Masking Ratio on Reconstruction", fontsize=18)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, "masking_ratio_vs_mse.png"), dpi=300)
        plt.close()
    
    # ======================== Experiment 2: åœºæ™¯æ€§èƒ½åˆ†æ ========================
    
    def experiment_scenario_wise_performance(self, scenario_names=None):
        """
        è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸­çš„æ€§èƒ½
        
        Args:
            scenario_names: åœºæ™¯åç§°åˆ—è¡¨
            
        Returns:
            results_dict: åŒ…å«æ¯ä¸ªåœºæ™¯çš„æ€§èƒ½æŒ‡æ ‡
        """
        if scenario_names is None:
            scenario_names = ['Stationary', 'High-Speed', 'Urban Macro']
        
        print("\nğŸŒ Experiment 2: åœºæ™¯æ€§èƒ½åˆ†æ")
        scenario_mse = []
        
        for scenario_idx in range(min(3, len(scenario_names))):
            scenario_data = self.masked_data[scenario_idx::3]
            labels = self.padded_data[scenario_idx::3]
            
            with torch.no_grad():
                inputs = torch.tensor(scenario_data).float().to(self.device)
                labels_tensor = torch.tensor(labels).float().to(self.device)
                outputs = self.model(inputs)
                mse = mean_squared_error(
                    labels_tensor.cpu().numpy().flatten(),
                    outputs.cpu().numpy().flatten()
                )
                scenario_mse.append(mse)
        
        results_df = pd.DataFrame({
            'Scenario': scenario_names,
            'MSE': scenario_mse
        })
        
        self._plot_scenario_results(results_df)
        print(f"âœ… å®Œæˆ: {len(scenario_names)}ä¸ªåœºæ™¯")
        
        return results_df
    
    def _plot_scenario_results(self, df):
        """ç»˜åˆ¶åœºæ™¯æ€§èƒ½"""
        plt.figure(figsize=(10, 6))
        plt.bar(df['Scenario'], df['MSE'], color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.8)
        plt.xlabel("Scenario", fontsize=14)
        plt.ylabel("MSE", fontsize=14)
        plt.title("Performance Across Scenarios", fontsize=16)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, "scenario_performance.png"), dpi=300)
        plt.close()
    
    # ======================== Experiment 5: å­è½½æ³¢æ€§èƒ½ ========================
    
    def experiment_subcarrier_performance(self, subcarrier_groups=None):
        """
        åˆ†æå­è½½æ³¢æ€§èƒ½
        
        Args:
            subcarrier_groups: å­è½½æ³¢åˆ†ç»„
            
        Returns:
            results_dict: åŒ…å«å­è½½æ³¢æ€§èƒ½çš„æŒ‡æ ‡
        """
        if subcarrier_groups is None:
            subcarrier_groups = [(i, i + 7) for i in range(0, 64, 8)]
        
        print("\nğŸ“¶ Experiment 5: å­è½½æ³¢æ€§èƒ½åˆ†æ")
        
        subcarrier_mse = []
        subcarrier_std = []
        subcarrier_max_error = []
        
        for group in tqdm(subcarrier_groups, desc="å­è½½æ³¢åˆ†ç»„"):
            group_data = self.padded_data[:, group[0]:group[1] + 1, :]
            masked_group_data, _ = self._mask_data(group_data, mask_ratio=0.15)
            
            errors = []
            with torch.no_grad():
                inputs = torch.tensor(masked_group_data).float().to(self.device)
                labels = torch.tensor(group_data).float().to(self.device)
                outputs = self.model(inputs)
                
                error = labels.cpu().numpy().flatten() - outputs.cpu().numpy().flatten()
                errors.extend(error)
                
                mse = mean_squared_error(
                    labels.cpu().numpy().flatten(),
                    outputs.cpu().numpy().flatten()
                )
            
            subcarrier_mse.append(mse)
            subcarrier_std.append(np.std(errors))
            subcarrier_max_error.append(np.max(np.abs(errors)))
        
        results_df = pd.DataFrame({
            'Subcarrier_Group': [f'{g[0]}-{g[1]}' for g in subcarrier_groups],
            'MSE': subcarrier_mse,
            'STD': subcarrier_std,
            'Max_Error': subcarrier_max_error
        })
        
        self._plot_subcarrier_results(results_df)
        print(f"âœ… å®Œæˆ: {len(subcarrier_groups)}ä¸ªå­è½½æ³¢åˆ†ç»„")
        
        return results_df
    
    def _plot_subcarrier_results(self, df):
        """ç»˜åˆ¶å­è½½æ³¢æ€§èƒ½"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        axes[0].bar(df['Subcarrier_Group'], df['MSE'], color='#1f77b4', alpha=0.8)
        axes[0].set_ylabel('MSE')
        axes[0].set_title('MSE Across Subcarrier Groups')
        axes[0].tick_params(axis='x', rotation=45)
        
        axes[1].bar(df['Subcarrier_Group'], df['STD'], color='#ff7f0e', alpha=0.8)
        axes[1].set_ylabel('Std Dev')
        axes[1].set_title('Error Std Dev Across Subcarrier Groups')
        axes[1].tick_params(axis='x', rotation=45)
        
        axes[2].bar(df['Subcarrier_Group'], df['Max_Error'], color='#2ca02c', alpha=0.8)
        axes[2].set_ylabel('Max Error')
        axes[2].set_title('Maximum Error Across Subcarrier Groups')
        axes[2].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, "subcarrier_performance.png"), dpi=300)
        plt.close()
    
    # ======================== Experiment 9: å¤šæ™®å‹’é²æ£’æ€§ ========================
    
    def experiment_doppler_shift_robustness(self, doppler_shifts=None, num_experiments=20):
        """
        æµ‹è¯•å¤šæ™®å‹’ç§»ä½é²æ£’æ€§
        
        Args:
            doppler_shifts: å¤šæ™®å‹’ç§»ä½å€¼ (Hz)
            num_experiments: å®éªŒæ¬¡æ•°
            
        Returns:
            results_df: åŒ…å«æ‰€æœ‰ç»“æœçš„ DataFrame
        """
        if doppler_shifts is None:
            doppler_shifts = np.linspace(50.0, 400.0, 20).round()
        
        print("\nğŸŒŠ Experiment 9: å¤šæ™®å‹’ç§»ä½é²æ£’æ€§")
        results = []
        
        for experiment in tqdm(range(num_experiments), desc="å®éªŒè¿›åº¦"):
            for doppler in doppler_shifts:
                # æ¨¡æ‹Ÿå¤šæ™®å‹’æ•ˆåº”
                noisy_data = self.padded_data + np.random.normal(
                    0, doppler / 1000, self.padded_data.shape
                )
                
                with torch.no_grad():
                    inputs = torch.tensor(noisy_data).float().to(self.device)
                    labels = torch.tensor(self.padded_data).float().to(self.device)
                    outputs = self.model(inputs)
                    mse = mean_squared_error(
                        labels.cpu().numpy().flatten(),
                        outputs.cpu().numpy().flatten()
                    )
                
                results.append({
                    'Doppler_Shift': doppler,
                    'MSE': mse,
                    'Experiment': experiment
                })
        
        results_df = pd.DataFrame(results)
        self._plot_doppler_results(results_df)
        
        print(f"âœ… å®Œæˆ: {len(results)}ä¸ªæ•°æ®ç‚¹")
        return results_df
    
    def _plot_doppler_results(self, df):
        """ç»˜åˆ¶å¤šæ™®å‹’ç»“æœ"""
        plt.figure(figsize=(12, 6))
        sns.lineplot(data=df, x='Doppler_Shift', y='MSE', errorbar='sd', err_style="band")
        plt.xlabel("Doppler Shift (Hz)", fontsize=16)
        plt.ylabel("Reconstruction MSE", fontsize=16)
        plt.title("Impact of Doppler Shift on Reconstruction", fontsize=18)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, "doppler_robustness.png"), dpi=300)
        plt.close()
    
    # ======================== Experiment 10: è·¨åœºæ™¯æ³›åŒ– ========================
    
    def experiment_cross_scenario_generalization(self, scenario_names=None):
        """
        æµ‹è¯•è·¨åœºæ™¯æ³›åŒ–èƒ½åŠ›
        
        Args:
            scenario_names: åœºæ™¯åç§°åˆ—è¡¨
            
        Returns:
            cross_mse: äº¤å‰éªŒè¯ç»“æœçŸ©é˜µ
        """
        if scenario_names is None:
            scenario_names = ['Stationary', 'High-Speed', 'Urban Macro']
        
        print("\nğŸ”„ Experiment 10: è·¨åœºæ™¯æ³›åŒ–èƒ½åŠ›")
        cross_mse = []
        
        for train_scenario_idx in range(min(3, len(scenario_names))):
            for test_scenario_idx in range(min(3, len(scenario_names))):
                test_data = self.padded_data[test_scenario_idx::3]
                test_masked, _ = self._mask_data(test_data, mask_ratio=0.15)
                
                with torch.no_grad():
                    inputs = torch.tensor(test_masked).float().to(self.device)
                    labels = torch.tensor(test_data).float().to(self.device)
                    outputs = self.model(inputs)
                    mse = mean_squared_error(
                        labels.cpu().numpy().flatten(),
                        outputs.cpu().numpy().flatten()
                    )
                    cross_mse.append({
                        'Train_Scenario': scenario_names[train_scenario_idx],
                        'Test_Scenario': scenario_names[test_scenario_idx],
                        'MSE': mse
                    })
        
        cross_df = pd.DataFrame(cross_mse)
        self._plot_generalization_results(cross_df, scenario_names)
        
        print(f"âœ… å®Œæˆ: {len(cross_mse)}ä¸ªåœºæ™¯å¯¹")
        return cross_df
    
    def _plot_generalization_results(self, df, scenario_names):
        """ç»˜åˆ¶æ³›åŒ–ç»“æœ"""
        pivot_df = df.pivot(index='Train_Scenario', columns='Test_Scenario', values='MSE')
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(pivot_df, annot=True, fmt='.6f', cmap='coolwarm', cbar_kws={'label': 'MSE'})
        plt.title("Cross-Scenario Generalization", fontsize=16)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, "generalization_heatmap.png"), dpi=300)
        plt.close()
    
    # ======================== Experiment 8: åŸºçº¿å¯¹æ¯” ========================
    
    def experiment_baseline_comparison(self):
        """
        ä¸åŸºçº¿æ¨¡å‹ï¼ˆLinear Regression, MLPï¼‰å¯¹æ¯”
        
        Returns:
            results_df: åŒ…å«æ‰€æœ‰æ¨¡å‹æ€§èƒ½çš„ DataFrame
        """
        print("\nâš–ï¸  Experiment 8: åŸºçº¿æ¨¡å‹å¯¹æ¯”")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        train_inputs = self.masked_data.reshape(-1, self.feature_dim)
        train_labels = self.padded_data.reshape(-1, self.feature_dim)
        
        # çº¿æ€§å›å½’
        print("  ğŸ”¹ è®­ç»ƒçº¿æ€§å›å½’...")
        linear_model = LinearRegression()
        linear_model.fit(train_inputs, train_labels)
        linear_mse = mean_squared_error(train_labels, linear_model.predict(train_inputs))
        
        # MLP
        print("  ğŸ”¹ è®­ç»ƒ MLP...")
        mlp_model = MLPRegressor(
            hidden_layer_sizes=(512,), 
            max_iter=100, 
            random_state=42, 
            verbose=0,
            early_stopping=True
        )
        mlp_model.fit(train_inputs, train_labels)
        mlp_mse = mean_squared_error(train_labels, mlp_model.predict(train_inputs))
        
        # CSIBERT
        with torch.no_grad():
            inputs = torch.tensor(self.masked_data).float().to(self.device)
            labels = torch.tensor(self.padded_data).float().to(self.device)
            outputs = self.model(inputs)
            csibert_mse = mean_squared_error(
                labels.cpu().numpy().flatten(),
                outputs.cpu().numpy().flatten()
            )
        
        results_df = pd.DataFrame({
            'Model': ['CSIBERT', 'Linear Regression', 'MLP'],
            'MSE': [csibert_mse, linear_mse, mlp_mse]
        })
        
        self._plot_baseline_results(results_df)
        print(f"âœ… å®Œæˆ: {len(results_df)}ä¸ªæ¨¡å‹å¯¹æ¯”")
        
        return results_df
    
    def _plot_baseline_results(self, df):
        """ç»˜åˆ¶åŸºçº¿å¯¹æ¯”"""
        plt.figure(figsize=(10, 6))
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
        plt.bar(df['Model'], df['MSE'], color=colors, alpha=0.8)
        plt.ylabel('MSE', fontsize=14)
        plt.title('Model Performance Comparison', fontsize=16)
        plt.xticks(rotation=15)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, "baseline_comparison.png"), dpi=300)
        plt.close()
    
    # ======================== Experiment 6: é”™è¯¯åˆ†å¸ƒåˆ†æ ========================
    
    def experiment_error_distribution(self, subcarrier_groups=None):
        """
        åˆ†æé”™è¯¯åˆ†å¸ƒ
        
        Args:
            subcarrier_groups: å­è½½æ³¢åˆ†ç»„
        """
        if subcarrier_groups is None:
            subcarrier_groups = [(i, i + 7) for i in range(0, 64, 8)]
        
        print("\nğŸ“Š Experiment 6: é”™è¯¯åˆ†å¸ƒåˆ†æ")
        
        plt.figure(figsize=(14, 8))
        
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
        linestyles = ['solid', 'dashed', 'dotted', 'dashdot', 'solid']
        
        for idx, group in enumerate(tqdm(subcarrier_groups, desc="å¤„ç†å­è½½æ³¢åˆ†ç»„")):
            group_data = self.padded_data[:, group[0]:group[1] + 1, :]
            masked_group_data, _ = self._mask_data(group_data, mask_ratio=0.15)
            
            errors = []
            with torch.no_grad():
                inputs = torch.tensor(masked_group_data).float().to(self.device)
                labels = torch.tensor(group_data).float().to(self.device)
                outputs = self.model(inputs)
                error = labels.cpu().numpy().flatten() - outputs.cpu().numpy().flatten()
                errors.extend(error)
            
            plt.hist(
                errors,
                bins=100,
                histtype='step',
                linestyle=linestyles[idx % len(linestyles)],
                color=colors[idx % len(colors)],
                label=f"Group {group[0]}-{group[1]}",
                linewidth=2
            )
        
        plt.xlabel("Reconstruction Error", fontsize=14)
        plt.ylabel("Frequency", fontsize=14)
        plt.title("Error Distribution Across Subcarrier Groups", fontsize=16)
        plt.legend(loc='upper right', fontsize=10)
        plt.grid(True, alpha=0.3)
        plt.xlim([-1.5, 1.5])
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, "error_distribution.png"), dpi=300)
        plt.close()
        
        print("âœ… å®Œæˆ: é”™è¯¯åˆ†å¸ƒå›¾å·²ä¿å­˜")
    
    # ======================== Experiment 4: æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ– ========================
    
    def experiment_attention_visualization(self, num_samples=5, layer_idx=None, head_idx=0):
        """
        å¯è§†åŒ–æ¨¡å‹çš„æ³¨æ„åŠ›æƒé‡
        
        Args:
            num_samples: å¯è§†åŒ–çš„æ ·æœ¬æ•°
            layer_idx: å±‚ç´¢å¼•
            head_idx: æ³¨æ„åŠ›å¤´ç´¢å¼•
        """
        print("\nğŸ‘ï¸  Experiment 4: æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæ³¨æ„åŠ›è¾“å‡º
        if not hasattr(self.model, 'output_attentions'):
            print("âš ï¸  æ¨¡å‹ä¸æ”¯æŒæ³¨æ„åŠ›æƒé‡è¾“å‡ºï¼Œè·³è¿‡æ­¤å®éªŒ")
            return
        
        for sample_idx in tqdm(range(num_samples), desc="ç”Ÿæˆæ³¨æ„åŠ›å›¾"):
            idx = np.random.randint(0, len(self.padded_data))
            sample_input = self.padded_data[idx:idx + 1]
            
            sample_input_tensor = torch.tensor(sample_input).float().to(self.device)
            
            # æ³¨æ„ï¼šéœ€è¦ä¿®æ”¹æ¨¡å‹ä»¥æ”¯æŒæ³¨æ„åŠ›è¾“å‡º
            with torch.no_grad():
                outputs = self.model(sample_input_tensor)
            
            # å¦‚æœæˆåŠŸè·å–æ³¨æ„åŠ›ï¼Œç»˜åˆ¶çƒ­å›¾
            # ï¼ˆè¿™éƒ¨åˆ†éœ€è¦æ ¹æ®å®é™…æ¨¡å‹å®ç°è°ƒæ•´ï¼‰
        
        print("âœ… å®Œæˆ: æ³¨æ„åŠ›å¯è§†åŒ–")
    
    def run_all_advanced_experiments(self):
        """è¿è¡Œæ‰€æœ‰é«˜çº§å®éªŒ"""
        print("\n" + "="*70)
        print("è¿è¡Œæ‰€æœ‰é«˜çº§ CSIBERT å®éªŒ")
        print("="*70 + "\n")
        
        results_summary = {}
        
        # Experiment 3
        try:
            results_summary['masking_ratio'] = self.experiment_masking_ratio_sensitivity()
        except Exception as e:
            print(f"âŒ Experiment 3 å¤±è´¥: {e}")
        
        # Experiment 2
        try:
            results_summary['scenario'] = self.experiment_scenario_wise_performance()
        except Exception as e:
            print(f"âŒ Experiment 2 å¤±è´¥: {e}")
        
        # Experiment 5
        try:
            results_summary['subcarrier'] = self.experiment_subcarrier_performance()
        except Exception as e:
            print(f"âŒ Experiment 5 å¤±è´¥: {e}")
        
        # Experiment 9
        try:
            results_summary['doppler'] = self.experiment_doppler_shift_robustness()
        except Exception as e:
            print(f"âŒ Experiment 9 å¤±è´¥: {e}")
        
        # Experiment 10
        try:
            results_summary['generalization'] = self.experiment_cross_scenario_generalization()
        except Exception as e:
            print(f"âŒ Experiment 10 å¤±è´¥: {e}")
        
        # Experiment 8
        try:
            results_summary['baseline'] = self.experiment_baseline_comparison()
        except Exception as e:
            print(f"âŒ Experiment 8 å¤±è´¥: {e}")
        
        # Experiment 6
        try:
            self.experiment_error_distribution()
        except Exception as e:
            print(f"âŒ Experiment 6 å¤±è´¥: {e}")
        
        # Experiment 4
        try:
            self.experiment_attention_visualization()
        except Exception as e:
            print(f"âŒ Experiment 4 å¤±è´¥: {e}")
        
        print("\n" + "="*70)
        print("âœ… æ‰€æœ‰é«˜çº§å®éªŒå·²å®Œæˆï¼")
        print(f"ğŸ“Š ç»“æœå·²ä¿å­˜è‡³ {self.output_dir}/ ç›®å½•")
        print("="*70 + "\n")
        
        return results_summary
